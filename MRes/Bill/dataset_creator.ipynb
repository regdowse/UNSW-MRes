{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61567ff6-f3d8-412c-ae6b-5ea18c4b766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/cot_ag_futures_2025-06-24_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-02-25_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-03-25_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-11-25_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-08-26_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-05-27_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-01-28_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-10-28_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-04-29_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-07-29_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-09-30_dataset.csv\n",
      "Saved: data/cot_ag_futures_2025-12-30_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import re, json, pandas as pd, numpy as np, os\n",
    "import pdfplumber\n",
    "\n",
    "pdf_dir = \"data_pdfs\"\n",
    "out_dir = \"data\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "pos_cols = [\n",
    "    \"prod_long\",\"prod_short\",\n",
    "    \"swap_long\",\"swap_short\",\"swap_spreading\",\n",
    "    \"mm_long\",\"mm_short\",\"mm_spreading\",\n",
    "    \"other_long\",\"other_short\",\"other_spreading\"\n",
    "]\n",
    "\n",
    "largest_cols = [\n",
    "    \"gross_4_long\",\"gross_4_short\",\"gross_8_long\",\"gross_8_short\",\n",
    "    \"net_4_long\",\"net_4_short\",\"net_8_long\",\"net_8_short\"\n",
    "]\n",
    "\n",
    "commodity_line_pat = re.compile(r\"^([A-Z0-9][A-Z0-9 .,&'\\/\\-]+?)\\s-\\s([A-Z0-9][A-Z0-9 .,&'\\/\\-]+?)\\s*$\")\n",
    "date_line_pat = re.compile(r\"^Disaggregated Commitments of Traders - Futures Only,\\s*(.+?)\\s*$\")\n",
    "contracts_line_pat = re.compile(r\"^\\s*:\\s*:\\(CONTRACTS? OF (.+?)\\)\\s*$\")\n",
    "\n",
    "positions_row_pat = re.compile(r\"^(All|Old|Other)\\s*:\\s*([0-9,]+)\\s*:\\s*([0-9,.\\- ]+?)\\s*$\")\n",
    "change_row_pat = re.compile(r\"^\\s*:\\s*([0-9,\\-]+)\\s*:\\s*([0-9,.\\- ]+?)\\s*$\")\n",
    "largest_row_pat = re.compile(r\"^(All|Old|Other)\\s*:\\s*([0-9.\\- ]+?)\\s*$\")\n",
    "\n",
    "def parse_int(s):\n",
    "    s = s.strip().replace(\",\", \"\")\n",
    "    if s in {\".\", \"\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_float(s):\n",
    "    s = s.strip().replace(\",\", \"\")\n",
    "    if s in {\".\", \"\"}:\n",
    "        return None\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_11_numbers(blob, floaty=False):\n",
    "    parts = [p for p in re.split(r\"\\s+\", blob.strip()) if p][:11]\n",
    "    vals = [parse_float(p) if floaty else parse_int(p) for p in parts]\n",
    "    vals += [None] * (11 - len(vals))\n",
    "    return dict(zip(pos_cols, vals))\n",
    "\n",
    "def parse_8_numbers(blob):\n",
    "    parts = [p for p in re.split(r\"\\s+\", blob.strip()) if p][:8]\n",
    "    vals = [parse_float(p) for p in parts]\n",
    "    vals += [None] * (8 - len(vals))\n",
    "    return dict(zip(largest_cols, vals))\n",
    "\n",
    "def ensure_struct(comm, exch, date, contract):\n",
    "    dataset.setdefault(comm, {\"exchange\": exch, \"report_date\": date, \"contract_spec\": contract, \"rows\": {}, \"change\": {}})\n",
    "    for sr in [\"All\",\"Old\",\"Other\"]:\n",
    "        dataset[comm][\"rows\"].setdefault(sr, {})\n",
    "\n",
    "def date_from_filename(fname):\n",
    "    # accept either DD:MM:YY or DD/MM/YY (just in case)\n",
    "    m = re.search(r\"(\\d{2})[:/](\\d{2})[:/](\\d{2})\", fname)\n",
    "    if not m:\n",
    "        raise ValueError(f\"No date found in filename: {fname}\")\n",
    "\n",
    "    d = datetime.strptime(m.group(0), \"%d:%m:%y\") if \":\" in m.group(0) else datetime.strptime(m.group(0), \"%d/%m/%y\")\n",
    "    return d.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "for pdf_file in sorted(f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")):\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    report_date_tag = date_from_filename(pdf_file)\n",
    "\n",
    "    # ---------- RESET STATE PER PDF ----------\n",
    "    all_lines = []\n",
    "    dataset = {}\n",
    "    current = None\n",
    "    current_exchange = None\n",
    "    current_report_date = None\n",
    "    current_contract_size = None\n",
    "    state = None\n",
    "    pending_change = False\n",
    "    # ----------------------------------------\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            txt = page.extract_text() or \"\"\n",
    "            for line in txt.splitlines():\n",
    "                all_lines.append(line.rstrip())\n",
    "\n",
    "    for line in all_lines:\n",
    "        m = commodity_line_pat.match(line)\n",
    "        if m:\n",
    "            current = m.group(1).strip()\n",
    "            current_exchange = m.group(2).strip()\n",
    "            current_contract_size = None\n",
    "            state = None\n",
    "            pending_change = False\n",
    "            ensure_struct(current, current_exchange, current_report_date, current_contract_size)\n",
    "            continue\n",
    "\n",
    "        if current is None:\n",
    "            continue\n",
    "\n",
    "        m = date_line_pat.match(line)\n",
    "        if m:\n",
    "            current_report_date = m.group(1).strip()\n",
    "            ensure_struct(current, current_exchange, current_report_date, current_contract_size)\n",
    "            continue\n",
    "\n",
    "        m = contracts_line_pat.match(line)\n",
    "        if m:\n",
    "            current_contract_size = m.group(1).strip()\n",
    "            ensure_struct(current, current_exchange, current_report_date, current_contract_size)\n",
    "            continue\n",
    "\n",
    "        if \"Positions\" in line and line.strip().endswith(\"Positions\"):\n",
    "            state = \"positions\"\n",
    "            continue\n",
    "        if \"Changes in Commitments from:\" in line:\n",
    "            pending_change = True\n",
    "            continue\n",
    "        if \"Percent of Open Interest Represented by Each Category of Trader\" in line:\n",
    "            state = \"percent\"\n",
    "            continue\n",
    "        if \"Number of Traders in Each Category\" in line:\n",
    "            state = \"traders\"\n",
    "            continue\n",
    "        if \"Percent of Open Interest Held by the Indicated Number of the Largest Traders\" in line:\n",
    "            state = \"largest\"\n",
    "            continue\n",
    "\n",
    "        if pending_change:\n",
    "            m = change_row_pat.match(line)\n",
    "            if m:\n",
    "                ensure_struct(current, current_exchange, current_report_date, current_contract_size)\n",
    "                dataset[current][\"change\"][\"open_interest\"] = parse_int(m.group(1))\n",
    "                dataset[current][\"change\"].update(parse_11_numbers(m.group(2), floaty=False))\n",
    "                pending_change = False\n",
    "            continue\n",
    "\n",
    "        m = positions_row_pat.match(line)\n",
    "        if m and state in {\"positions\",\"percent\",\"traders\"}:\n",
    "            sr = m.group(1)\n",
    "            open_interest = m.group(2)\n",
    "            blob = m.group(3)\n",
    "            ensure_struct(current, current_exchange, current_report_date, current_contract_size)\n",
    "            if state == \"positions\":\n",
    "                dataset[current][\"rows\"][sr][\"open_interest\"] = parse_int(open_interest)\n",
    "                dataset[current][\"rows\"][sr].update(parse_11_numbers(blob, floaty=False))\n",
    "            elif state == \"percent\":\n",
    "                dataset[current][\"rows\"][sr].update({f\"pct_{k}\": v for k,v in parse_11_numbers(blob, floaty=True).items()})\n",
    "            elif state == \"traders\":\n",
    "                dataset[current][\"rows\"][sr].update({f\"traders_{k}\": v for k,v in parse_11_numbers(blob, floaty=False).items()})\n",
    "            continue\n",
    "\n",
    "        if state == \"largest\":\n",
    "            m = largest_row_pat.match(line)\n",
    "            if m:\n",
    "                sr = m.group(1)\n",
    "                blob = m.group(2)\n",
    "                if re.search(r\"[A-Za-z]\", blob):\n",
    "                    continue\n",
    "                ensure_struct(current, current_exchange, current_report_date, current_contract_size)\n",
    "                dataset[current][\"rows\"][sr].update({f\"largest_{k}\": v for k,v in parse_8_numbers(blob).items()})\n",
    "                continue\n",
    "\n",
    "    records = []\n",
    "    for comm, info in dataset.items():\n",
    "        for sr, row in info[\"rows\"].items():\n",
    "            rec = {\n",
    "                \"commodity\": comm,\n",
    "                \"exchange\": info.get(\"exchange\"),\n",
    "                \"report_date\": info.get(\"report_date\"),\n",
    "                \"contract_spec\": info.get(\"contract_spec\"),\n",
    "                \"subreport\": sr,\n",
    "                \"change_open_interest\": info.get(\"change\", {}).get(\"open_interest\"),\n",
    "            }\n",
    "            for k in pos_cols:\n",
    "                rec[f\"change_{k}\"] = info.get(\"change\", {}).get(k)\n",
    "            rec.update(row)\n",
    "            records.append(rec)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    desired = (\n",
    "        [\"commodity\",\"exchange\",\"report_date\",\"contract_spec\",\"subreport\",\"open_interest\"]\n",
    "        + [\"change_open_interest\"] + [f\"change_{k}\" for k in pos_cols]\n",
    "        + pos_cols\n",
    "        + [f\"pct_{k}\" for k in pos_cols]\n",
    "        + [f\"traders_{k}\" for k in pos_cols]\n",
    "        + [f\"largest_{k}\" for k in largest_cols]\n",
    "    )\n",
    "    ordered = [c for c in desired if c in df.columns] + [c for c in df.columns if c not in desired]\n",
    "    df = df[ordered]\n",
    "\n",
    "    out_csv = os.path.join(out_dir, f\"cot_ag_futures_{report_date_tag}_dataset.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"Saved: {out_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv 3.10)",
   "language": "python",
   "name": "myenv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
