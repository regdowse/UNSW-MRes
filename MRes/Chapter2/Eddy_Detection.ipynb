{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd191a7f-a5b0-47fe-9403-bc957878889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "import netCDF4 as nc\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0abc9c-2989-4234-93fa-f245086e935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nencioli(u, v, lon, lat, a, b):\n",
    "    \"\"\"\n",
    "    Identify the points in the domain which satisfy the four velocity constraints for eddy detection.\n",
    "\n",
    "    Parameters:\n",
    "    - u, v: 2D velocity fields for u and v components\n",
    "    - lon, lat: Longitude and Latitude matrices\n",
    "    - mask: Matrix defining sea (1) and land points (0)\n",
    "    - a, b: Parameters used for constraints\n",
    "\n",
    "    Returns:\n",
    "    - eddy_uv: Positions that satisfy the first two constraints (for debugging)\n",
    "    - eddy_c: Positions satisfying the first three constraints (for debugging)\n",
    "    - eddy: Positions of the eddy centers with their type (cyclonic=1, anticyclonic=-1) (opposite for me)\n",
    "    \"\"\"\n",
    "\n",
    "    borders = max(a, b) + 1\n",
    "\n",
    "    # Compute velocity magnitude\n",
    "    vel = np.sqrt(u**2 + v**2)\n",
    "\n",
    "    # Initialize arrays for storing eddy centers\n",
    "    eddy_uv = np.zeros((0, 2))\n",
    "    eddy_c = np.zeros((0, 2))\n",
    "    eddy = np.zeros((0, 3))\n",
    "\n",
    "    # Get domain dimensions\n",
    "    bound = vel.shape\n",
    "\n",
    "    # Loop through each latitudinal section\n",
    "    for i in range(borders, len(v) - borders + 1):\n",
    "        wrk = v[i, :]  # Latitudinal section of v\n",
    "\n",
    "        # First constraint: zero crossing in v component\n",
    "        s = np.sign(wrk)\n",
    "        indx = np.where(np.diff(s) != 0)[0]\n",
    "        indx = indx[(indx >= borders) & (indx < len(wrk) - borders)]\n",
    "\n",
    "        for ii in indx:\n",
    "            var = 0  # Eddy type (0 = no eddy, 1 = cyclonic, -1 = anticyclonic)\n",
    "            if wrk[ii] >= 0:  # Anticyclonic\n",
    "                if wrk[ii - a] > wrk[ii] and wrk[ii + 1 + a] < wrk[ii + 1]:\n",
    "                    var = -1\n",
    "            elif wrk[ii] < 0:  # Cyclonic\n",
    "                if wrk[ii - a] < wrk[ii] and wrk[ii + 1 + a] > wrk[ii + 1]:\n",
    "                    var = 1\n",
    "\n",
    "            # Second constraint: u component reversal\n",
    "            if var != 0:\n",
    "                if var == -1:\n",
    "                    if (u[i - a, ii] <= 0 and u[i - a, ii] <= u[i - 1, ii] and\n",
    "                        u[i + a, ii] >= 0 and u[i + a, ii] >= u[i + 1, ii]):\n",
    "                        eddy_uv = np.vstack([eddy_uv, [lat[i, ii], lon[i, ii]], [lat[i, ii + 1], lon[i, ii + 1]]])\n",
    "                    else:\n",
    "                        var = 0\n",
    "                elif var == 1:\n",
    "                    if (u[i - a, ii] >= 0 and u[i - a, ii] >= u[i - 1, ii] and\n",
    "                        u[i + a, ii] <= 0 and u[i + a, ii] <= u[i + 1, ii]):\n",
    "                        eddy_uv = np.vstack([eddy_uv, [lat[i, ii], lon[i, ii]], [lat[i, ii + 1], lon[i, ii + 1]]])\n",
    "                    else:\n",
    "                        var = 0\n",
    "\n",
    "                # Third constraint: velocity minimum\n",
    "                if var != 0:\n",
    "                    srch = vel[i - b:i + b, ii - b:ii + b + 1]\n",
    "                    slat = lat[i - b:i + b, ii - b:ii + b + 1]\n",
    "                    slon = lon[i - b:i + b, ii - b:ii + b + 1]\n",
    "                    X, Y = np.unravel_index(np.argmin(srch), srch.shape)\n",
    "                    srch2 = vel[max(i - b + X - 1 - b, 0):min(i - b + X - 1 + b, bound[0]),\n",
    "                                max(ii - b + Y - 1 - b, 0):min(ii - b + Y - 1 + b, bound[1])]\n",
    "\n",
    "                    if np.min(srch2) == np.min(srch):\n",
    "                        eddy_c = np.vstack([eddy_c, [slat[X, Y], slon[X, Y]]])\n",
    "                    else:\n",
    "                        var = 0\n",
    "\n",
    "                # Fourth constraint: vector rotation (simplified version)\n",
    "                d = a - 1\n",
    "                if var != 0:\n",
    "                    # Find indices of the estimated center in the large domain\n",
    "                    i1, i2 = np.where((lat == slat[X, Y]) & (lon == slon[X, Y]))\n",
    "\n",
    "                    i1, i2 = int(i1[0]), int(i2[0])\n",
    "                    \n",
    "                    # Extract velocities within \"a-1\" points from the estimated center\n",
    "                    u_small = u[max(i1 - d, 0):min(i1 + d, bound[0]), max(i2 - d, 0):min(i2 + d, bound[1])]\n",
    "                    v_small = v[max(i1 - d, 0):min(i1 + d, bound[0]), max(i2 - d, 0):min(i2 + d, bound[1])]\n",
    "                    \n",
    "                    # Apply constraint only if there are no NaNs in u_small\n",
    "                    if not np.isnan(u_small).any():\n",
    "                        # Boundary velocities\n",
    "                        u_bound = np.concatenate([u_small[0, :], u_small[1:, -1], u_small[-1, -2::-1], u_small[-2::-1, 0]])\n",
    "                        v_bound = np.concatenate([v_small[0, :], v_small[1:, -1], v_small[-1, -2::-1], v_small[-2::-1, 0]])\n",
    "\n",
    "                        # Vector defining which quadrant each boundary vector belongs to\n",
    "                        quadrants = np.zeros_like(u_bound)\n",
    "                        quadrants[(u_bound >= 0) & (v_bound >= 0)] = 1\n",
    "                        quadrants[(u_bound < 0) & (v_bound >= 0)] = 2\n",
    "                        quadrants[(u_bound < 0) & (v_bound < 0)] = 3\n",
    "                        quadrants[(u_bound >= 0) & (v_bound < 0)] = 4\n",
    "                        \n",
    "                        # Identify the first fourth quadrant vector\n",
    "                        spin = np.where(quadrants == 4)[0]\n",
    "                        \n",
    "                        # Apply the constraint only if the rotation is complete and not all vectors are in the fourth quadrant\n",
    "                        if spin.size > 0 and spin.size != quadrants.size:\n",
    "                            # If vectors start in the 4th quadrant, add 4 to all quadrant positions after the first occurrence\n",
    "                            if spin[0] == 0:\n",
    "                                spin = np.where(quadrants != 4)[0]\n",
    "                                spin = spin[0] - 1\n",
    "                                \n",
    "                            if not isinstance(spin, np.ndarray):\n",
    "                                spin = np.array([int(spin)])\n",
    "                            quadrants[spin[-1] + 1:] += 4\n",
    "                            \n",
    "                            # Inspect vector rotation: no consecutive vectors should be more than one quadrant apart\n",
    "                            # and there should be no backward rotation\n",
    "                            if not np.any(np.diff(quadrants) > 1) and not np.any(np.diff(quadrants) < 0):\n",
    "                                eddy = np.vstack([eddy, [slat[X, Y], slon[X, Y], var]])\n",
    "\n",
    "\n",
    "    # Process eddy results (sorting and removing duplicates)\n",
    "    eddy = np.unique(eddy, axis=0)\n",
    "    eddy_uv = np.unique(eddy_uv, axis=0)\n",
    "    eddy_c = np.unique(eddy_c, axis=0)\n",
    "    # Adjust for the Southern Hemisphere (flip cyclonic/anticyclonic labels)\n",
    "    # eddy[eddy[:, 0] < 0, 2] = -eddy[eddy[:, 0] < 0, 2]\n",
    "    eddy[:, 2] = -eddy[:, 2]\n",
    "    # Swap for personal preference \n",
    "    eddy[:, [0, 1]] = eddy[:, [1, 0]]\n",
    "\n",
    "    return eddy_uv, eddy_c, eddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268108dd-78f0-413e-b983-240979b1c7d5",
   "metadata": {},
   "source": [
    "#### Getting the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27963b8-ac7c-4334-a984-ccbbe86af6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'/srv/scratch/z3533156/26year_BRAN2020/outer_avg_01461.nc'\n",
    "\n",
    "dataset = nc.Dataset(fname)\n",
    "\n",
    "lon_rho = np.transpose(dataset.variables['lon_rho'], axes=(1, 0))\n",
    "lat_rho = np.transpose(dataset.variables['lat_rho'], axes=(1, 0))\n",
    "angle = dataset.variables['angle'][0, 0]\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    EARTH_RADIUS = 6357\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    return EARTH_RADIUS * 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "j_mid = lon_rho.shape[1] // 2\n",
    "i_mid = lon_rho.shape[0] // 2\n",
    "\n",
    "dx = distance(lat_rho[:-1, j_mid], lon_rho[:-1, j_mid],\n",
    "              lat_rho[1:, j_mid], lon_rho[1:, j_mid])\n",
    "dy = distance(lat_rho[i_mid, :-1], lon_rho[i_mid, :-1],\n",
    "              lat_rho[i_mid, 1:], lon_rho[i_mid, 1:])\n",
    "\n",
    "x_grid = np.insert(np.cumsum(dx), 0, 0)\n",
    "y_grid = np.insert(np.cumsum(dy), 0, 0)\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid, indexing='ij')\n",
    "\n",
    "res = 1  # 1 km resolution\n",
    "x_new = np.arange(0, x_grid[-1], res)\n",
    "y_new = np.arange(0, y_grid[-1], res)\n",
    "X_new, Y_new = np.meshgrid(x_new, y_new, indexing='ij')\n",
    "new_points = np.column_stack((X_new.ravel(), Y_new.ravel()))\n",
    "\n",
    "interp_lon = RegularGridInterpolator((x_grid, y_grid), lon_rho,\n",
    "                                     method='linear', bounds_error=False, fill_value=np.nan)\n",
    "interp_lat = RegularGridInterpolator((x_grid, y_grid), lat_rho,\n",
    "                                     method='linear', bounds_error=False, fill_value=np.nan)\n",
    "\n",
    "lon_new = interp_lon(new_points).reshape(len(x_new), len(y_new))\n",
    "lat_new = interp_lat(new_points).reshape(len(x_new), len(y_new))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284bfb5-ab6e-4180-ae42-94fcc23dea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_uv(u, v, x_grid, y_grid, X_new, Y_new, angle):\n",
    "    u_east = np.where(u > 1e30, np.nan, u).astype(float)\n",
    "    v_north = np.where(v > 1e30, np.nan, v).astype(float)\n",
    "\n",
    "    u_rot = v_north * np.sin(angle) + u_east * np.cos(angle)\n",
    "    v_rot = v_north * np.cos(angle) - u_east * np.sin(angle)\n",
    "\n",
    "    shape_new = X_new.shape\n",
    "    new_points = np.column_stack((X_new.ravel(), Y_new.ravel()))\n",
    "\n",
    "    interp_u = RegularGridInterpolator((x_grid, y_grid), u_rot,\n",
    "                                       method='linear', bounds_error=False, fill_value=np.nan)\n",
    "    interp_v = RegularGridInterpolator((x_grid, y_grid), v_rot,\n",
    "                                       method='linear', bounds_error=False, fill_value=np.nan)\n",
    "\n",
    "    u_new = interp_u(new_points).reshape(shape_new)\n",
    "    v_new = interp_v(new_points).reshape(shape_new)\n",
    "\n",
    "    return u_new, v_new\n",
    "\n",
    "def create_velocity_dic(start_day, num_days, x_grid, y_grid, X_new, Y_new, angle):\n",
    "    ROMS_velocity_dic = {}\n",
    "    for day in range(start_day, start_day + num_days + 1):\n",
    "        fnumber = 1461 + ((day - 1462) // 30)*30\n",
    "        fname = f'/srv/scratch/z3533156/26year_BRAN2020/outer_avg_{fnumber:05}.nc'\n",
    "        dataset = nc.Dataset(fname)\n",
    "        u_east = np.transpose(dataset['u_eastward'][:].data, axes=(3, 2, 1, 0))[:, :, -1, :].squeeze()\n",
    "        v_north = np.transpose(dataset['v_northward'][:].data, axes=(3, 2, 1, 0))[:, :, -1, :].squeeze()\n",
    "        ocean_time = dataset.variables['ocean_time'][:].data / 86400\n",
    "        t = np.where(day==ocean_time)[0][0]\n",
    "        if t.size != 0:\n",
    "            u, v = u_east[:, :, t], v_north[:, :, t]\n",
    "            u_new, v_new = interpolate_uv(u, v, x_grid, y_grid, X_new, Y_new, angle)\n",
    "            ROMS_velocity_dic[day] = {'u': u_new, 'v': v_new, 'fname': fname, 't': t}\n",
    "    return ROMS_velocity_dic\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "start_day, num_days = 5480, 5170     # last valid day 10650 (10641 excluding the small end file)\n",
    "ROMS_velocity_dic = create_velocity_dic(start_day, num_days, x_grid, y_grid, X_new, Y_new, angle)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00737785-8ca5-4636-9cb1-c8565ad07a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nenc_dataframe(ROMS_velocity_dic, X_new, Y_new, lon_new, lat_new):\n",
    "    rows = []\n",
    "    for day, data in ROMS_velocity_dic.items():\n",
    "        u0, v0 = data['u'], data['v']\n",
    "        # nencioli returns a tuple; take index 2 for neddy\n",
    "        neddy = nencioli(u0.T, v0.T, X_new.T, Y_new.T, 4, 3)[2]\n",
    "        # Sort so that the highest second-column value comes first\n",
    "        neddy = neddy[neddy[:, 1].argsort()[::-1]]\n",
    "        \n",
    "        for idx, (nxc0, nyc0, cyc_indicator) in enumerate(neddy):\n",
    "            cyc_value = 'CE' if cyc_indicator == 1 else 'AE'\n",
    "            nic_idx, njc_idx = np.where((X_new == nxc0) & (Y_new == nyc0))\n",
    "            if nic_idx.size:\n",
    "                nic0, njc0 = nic_idx[0], njc_idx[0]\n",
    "            else:\n",
    "                nic0, njc0 = np.nan, np.nan\n",
    "            \n",
    "            rows.append({\n",
    "                'Eddy': idx,\n",
    "                'Day': day,\n",
    "                'Cyc': cyc_value,\n",
    "                'nLon': lon_new[nic0, njc0],\n",
    "                'nLat': lat_new[nic0, njc0],\n",
    "                'nxc': nxc0,\n",
    "                'nyc': nyc0,\n",
    "                'nic': nic0,\n",
    "                'njc': njc0\n",
    "            })\n",
    "        if day % 20 == 0:\n",
    "            print(day)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "df_nenc = build_nenc_dataframe(ROMS_velocity_dic, X_new, Y_new, lon_new, lat_new)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76fb5e-a07e-4912-ae33-5d8e5cc80818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def espra(xi, yi, ui, vi):\n",
    "\n",
    "    if np.any(np.isnan(ui)):\n",
    "        return np.nan, np.nan, np.array([[np.nan, np.nan], [np.nan, np.nan]]), np.nan\n",
    "    \n",
    "    from scipy.optimize import least_squares\n",
    "\n",
    "    def residuals(params, x, y, u_i, v_i):\n",
    "        x0, y0, q11, q12, q22 = params\n",
    "        u = -2 * q22 * (y - y0) - 2 * q12 * (x - x0)\n",
    "        v =  2 * q11 * (x - x0) + 2 * q12 * (y - y0)\n",
    "        return np.concatenate([(u - u_i), (v - v_i)])\n",
    "\n",
    "    def fit_params(x, y, u_i, v_i):\n",
    "        x0_init, y0_init = np.mean(x), np.mean(y)\n",
    "        q11_init, q12_init, q22_init = 1.0, 0.0, 1.0  # Initial guesses\n",
    "        params_init = [x0_init, y0_init, q11_init, q12_init, q22_init]\n",
    "        result = least_squares(residuals, params_init, args=(x, y, u_i, v_i))\n",
    "        return result.x \n",
    "\n",
    "    x0, y0, q11, q12, q22 = fit_params(xi, yi, ui, vi)\n",
    "\n",
    "    w = 2*(q11 + q22)\n",
    "\n",
    "    Q = np.array([[q11, q12], [q12, q22]])\n",
    "    \n",
    "    return x0, y0, Q, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168478c0-673a-4743-aed1-65b6e9ef7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nenc_dataframe(df_nenc, ROMS_velocity_dic, X_new, Y_new):\n",
    "\n",
    "    df_data = df_nenc.copy()\n",
    "    for day in df_data['Day'].unique():\n",
    "        for e in df_data[df_data['Day'] == day]['Eddy'].unique():\n",
    "            # Get eddy location from the first row for this day/eddy combination.\n",
    "            row = df_data[(df_data['Day'] == day) & (df_data['Eddy'] == e)].iloc[0]\n",
    "            nxc, nyc = row['nxc'], row['nyc']\n",
    "            \n",
    "            # Try successive thresholds if NaNs are encountered in the velocity data.\n",
    "            for thresh in (30, 20, 10):\n",
    "                mask = np.hypot(nxc - X_new, nyc - Y_new) <= thresh\n",
    "                ut, vt = ROMS_velocity_dic[day]['u'], ROMS_velocity_dic[day]['v']\n",
    "                ui, vi = ut[mask], vt[mask]\n",
    "                xi, yi = X_new[mask], Y_new[mask]\n",
    "                if not np.any(np.isnan(ui)):\n",
    "                    break\n",
    "            \n",
    "            # Compute output values with espra.\n",
    "            x0, y0, Q, w = espra(xi, yi, ui, vi)\n",
    "            if np.hypot(nxc - x0, nyc - y0) > 50:\n",
    "                x0, y0, Q, w = np.nan, np.nan, np.array([[np.nan, np.nan],\n",
    "                                                           [np.nan, np.nan]]), np.nan\n",
    "                \n",
    "            # Update DataFrame for this day/eddy.\n",
    "            update_mask = (df_data['Day'] == day) & (df_data['Eddy'] == e)\n",
    "            df_data.loc[update_mask, 'x0'] = x0\n",
    "            df_data.loc[update_mask, 'y0'] = y0\n",
    "            df_data.loc[update_mask, 'q11'] = Q[0, 0]\n",
    "            df_data.loc[update_mask, 'q12'] = Q[1, 0]\n",
    "            df_data.loc[update_mask, 'q22'] = Q[1, 1]\n",
    "            df_data.loc[update_mask, 'w'] = w\n",
    "\n",
    "        if day % 20 == 0:\n",
    "            print(day)\n",
    "\n",
    "    return df_data\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "df_data = update_nenc_dataframe(df_nenc, ROMS_velocity_dic, X_new, Y_new)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "\n",
    "del df_nenc, ROMS_velocity_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94641451-78dd-4479-b6df-dd0e30295fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_pickle(f\"/srv/scratch/z5297792/Chapter2/df_data_{start_day}_{start_day+num_days}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51053b-50c1-4577-a10f-536988023be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
