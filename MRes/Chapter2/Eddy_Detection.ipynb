{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd191a7f-a5b0-47fe-9403-bc957878889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "import netCDF4 as nc\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/z5297792/UNSW-MRes/MRes/modules\") \n",
    "from utils import dopioe, rossby_number, calc_tang_vel, find_directional_radii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0abc9c-2989-4234-93fa-f245086e935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nencioli(u, v, lon, lat, a, b):\n",
    "    \"\"\"\n",
    "    Identify the points in the domain which satisfy the four velocity constraints for eddy detection.\n",
    "\n",
    "    Parameters:\n",
    "    - u, v: 2D velocity fields for u and v components\n",
    "    - lon, lat: Longitude and Latitude matrices\n",
    "    - mask: Matrix defining sea (1) and land points (0)\n",
    "    - a, b: Parameters used for constraints\n",
    "\n",
    "    Returns:\n",
    "    - eddy_uv: Positions that satisfy the first two constraints (for debugging)\n",
    "    - eddy_c: Positions satisfying the first three constraints (for debugging)\n",
    "    - eddy: Positions of the eddy centers with their type (cyclonic=1, anticyclonic=-1) (opposite for me)\n",
    "    \"\"\"\n",
    "\n",
    "    borders = max(a, b) + 1\n",
    "\n",
    "    # Compute velocity magnitude\n",
    "    vel = np.sqrt(u**2 + v**2)\n",
    "\n",
    "    # Initialize arrays for storing eddy centers\n",
    "    eddy_uv = np.zeros((0, 2))\n",
    "    eddy_c = np.zeros((0, 2))\n",
    "    eddy = np.zeros((0, 3))\n",
    "\n",
    "    # Get domain dimensions\n",
    "    bound = vel.shape\n",
    "\n",
    "    # Loop through each latitudinal section\n",
    "    for i in range(borders, len(v) - borders + 1):\n",
    "        wrk = v[i, :]  # Latitudinal section of v\n",
    "\n",
    "        # First constraint: zero crossing in v component\n",
    "        s = np.sign(wrk)\n",
    "        indx = np.where(np.diff(s) != 0)[0]\n",
    "        indx = indx[(indx >= borders) & (indx < len(wrk) - borders)]\n",
    "\n",
    "        for ii in indx:\n",
    "            var = 0  # Eddy type (0 = no eddy, 1 = cyclonic, -1 = anticyclonic)\n",
    "            if wrk[ii] >= 0:  # Anticyclonic\n",
    "                if wrk[ii - a] > wrk[ii] and wrk[ii + 1 + a] < wrk[ii + 1]:\n",
    "                    var = -1\n",
    "            elif wrk[ii] < 0:  # Cyclonic\n",
    "                if wrk[ii - a] < wrk[ii] and wrk[ii + 1 + a] > wrk[ii + 1]:\n",
    "                    var = 1\n",
    "\n",
    "            # Second constraint: u component reversal\n",
    "            if var != 0:\n",
    "                if var == -1:\n",
    "                    if (u[i - a, ii] <= 0 and u[i - a, ii] <= u[i - 1, ii] and\n",
    "                        u[i + a, ii] >= 0 and u[i + a, ii] >= u[i + 1, ii]):\n",
    "                        eddy_uv = np.vstack([eddy_uv, [lat[i, ii], lon[i, ii]], [lat[i, ii + 1], lon[i, ii + 1]]])\n",
    "                    else:\n",
    "                        var = 0\n",
    "                elif var == 1:\n",
    "                    if (u[i - a, ii] >= 0 and u[i - a, ii] >= u[i - 1, ii] and\n",
    "                        u[i + a, ii] <= 0 and u[i + a, ii] <= u[i + 1, ii]):\n",
    "                        eddy_uv = np.vstack([eddy_uv, [lat[i, ii], lon[i, ii]], [lat[i, ii + 1], lon[i, ii + 1]]])\n",
    "                    else:\n",
    "                        var = 0\n",
    "\n",
    "                # Third constraint: velocity minimum\n",
    "                if var != 0:\n",
    "                    srch = vel[i - b:i + b, ii - b:ii + b + 1]\n",
    "                    slat = lat[i - b:i + b, ii - b:ii + b + 1]\n",
    "                    slon = lon[i - b:i + b, ii - b:ii + b + 1]\n",
    "                    X, Y = np.unravel_index(np.argmin(srch), srch.shape)\n",
    "                    srch2 = vel[max(i - b + X - 1 - b, 0):min(i - b + X - 1 + b, bound[0]),\n",
    "                                max(ii - b + Y - 1 - b, 0):min(ii - b + Y - 1 + b, bound[1])]\n",
    "\n",
    "                    if np.min(srch2) == np.min(srch):\n",
    "                        eddy_c = np.vstack([eddy_c, [slat[X, Y], slon[X, Y]]])\n",
    "                    else:\n",
    "                        var = 0\n",
    "\n",
    "                # Fourth constraint: vector rotation (simplified version)\n",
    "                d = a - 1\n",
    "                if var != 0:\n",
    "                    # Find indices of the estimated center in the large domain\n",
    "                    i1, i2 = np.where((lat == slat[X, Y]) & (lon == slon[X, Y]))\n",
    "\n",
    "                    i1, i2 = int(i1[0]), int(i2[0])\n",
    "                    \n",
    "                    # Extract velocities within \"a-1\" points from the estimated center\n",
    "                    u_small = u[max(i1 - d, 0):min(i1 + d, bound[0]), max(i2 - d, 0):min(i2 + d, bound[1])]\n",
    "                    v_small = v[max(i1 - d, 0):min(i1 + d, bound[0]), max(i2 - d, 0):min(i2 + d, bound[1])]\n",
    "                    \n",
    "                    # Apply constraint only if there are no NaNs in u_small\n",
    "                    if not np.isnan(u_small).any():\n",
    "                        # Boundary velocities\n",
    "                        u_bound = np.concatenate([u_small[0, :], u_small[1:, -1], u_small[-1, -2::-1], u_small[-2::-1, 0]])\n",
    "                        v_bound = np.concatenate([v_small[0, :], v_small[1:, -1], v_small[-1, -2::-1], v_small[-2::-1, 0]])\n",
    "\n",
    "                        # Vector defining which quadrant each boundary vector belongs to\n",
    "                        quadrants = np.zeros_like(u_bound)\n",
    "                        quadrants[(u_bound >= 0) & (v_bound >= 0)] = 1\n",
    "                        quadrants[(u_bound < 0) & (v_bound >= 0)] = 2\n",
    "                        quadrants[(u_bound < 0) & (v_bound < 0)] = 3\n",
    "                        quadrants[(u_bound >= 0) & (v_bound < 0)] = 4\n",
    "                        \n",
    "                        # Identify the first fourth quadrant vector\n",
    "                        spin = np.where(quadrants == 4)[0]\n",
    "                        \n",
    "                        # Apply the constraint only if the rotation is complete and not all vectors are in the fourth quadrant\n",
    "                        if spin.size > 0 and spin.size != quadrants.size:\n",
    "                            # If vectors start in the 4th quadrant, add 4 to all quadrant positions after the first occurrence\n",
    "                            if spin[0] == 0:\n",
    "                                spin = np.where(quadrants != 4)[0]\n",
    "                                spin = spin[0] - 1\n",
    "                                \n",
    "                            if not isinstance(spin, np.ndarray):\n",
    "                                spin = np.array([int(spin)])\n",
    "                            quadrants[spin[-1] + 1:] += 4\n",
    "                            \n",
    "                            # Inspect vector rotation: no consecutive vectors should be more than one quadrant apart\n",
    "                            # and there should be no backward rotation\n",
    "                            if not np.any(np.diff(quadrants) > 1) and not np.any(np.diff(quadrants) < 0):\n",
    "                                eddy = np.vstack([eddy, [slat[X, Y], slon[X, Y], var]])\n",
    "\n",
    "\n",
    "    # Process eddy results (sorting and removing duplicates)\n",
    "    eddy = np.unique(eddy, axis=0)\n",
    "    eddy_uv = np.unique(eddy_uv, axis=0)\n",
    "    eddy_c = np.unique(eddy_c, axis=0)\n",
    "    # Adjust for the Southern Hemisphere (flip cyclonic/anticyclonic labels)\n",
    "    # eddy[eddy[:, 0] < 0, 2] = -eddy[eddy[:, 0] < 0, 2]\n",
    "    eddy[:, 2] = -eddy[:, 2]\n",
    "    # Swap for personal preference \n",
    "    eddy[:, [0, 1]] = eddy[:, [1, 0]]\n",
    "\n",
    "    return eddy_uv, eddy_c, eddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268108dd-78f0-413e-b983-240979b1c7d5",
   "metadata": {},
   "source": [
    "#### Getting the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27963b8-ac7c-4334-a984-ccbbe86af6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'/srv/scratch/z3533156/26year_BRAN2020/outer_avg_01461.nc'\n",
    "\n",
    "dataset = nc.Dataset(fname)\n",
    "\n",
    "lon_rho = np.transpose(dataset.variables['lon_rho'], axes=(1, 0))\n",
    "lat_rho = np.transpose(dataset.variables['lat_rho'], axes=(1, 0))\n",
    "angle = dataset.variables['angle'][0, 0]\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    EARTH_RADIUS = 6357\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    return EARTH_RADIUS * 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "j_mid = lon_rho.shape[1] // 2\n",
    "i_mid = lon_rho.shape[0] // 2\n",
    "\n",
    "dx = distance(lat_rho[:-1, j_mid], lon_rho[:-1, j_mid],\n",
    "              lat_rho[1:, j_mid], lon_rho[1:, j_mid])\n",
    "dy = distance(lat_rho[i_mid, :-1], lon_rho[i_mid, :-1],\n",
    "              lat_rho[i_mid, 1:], lon_rho[i_mid, 1:])\n",
    "\n",
    "x_grid = np.insert(np.cumsum(dx), 0, 0)\n",
    "y_grid = np.insert(np.cumsum(dy), 0, 0)\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid, indexing='ij')\n",
    "\n",
    "res = 1  # 1 km resolution\n",
    "x_new = np.arange(0, x_grid[-1], res)\n",
    "y_new = np.arange(0, y_grid[-1], res)\n",
    "X_new, Y_new = np.meshgrid(x_new, y_new, indexing='ij')\n",
    "new_points = np.column_stack((X_new.ravel(), Y_new.ravel()))\n",
    "\n",
    "interp_lon = RegularGridInterpolator((x_grid, y_grid), lon_rho,\n",
    "                                     method='linear', bounds_error=False, fill_value=np.nan)\n",
    "interp_lat = RegularGridInterpolator((x_grid, y_grid), lat_rho,\n",
    "                                     method='linear', bounds_error=False, fill_value=np.nan)\n",
    "\n",
    "lon_new = interp_lon(new_points).reshape(len(x_new), len(y_new))\n",
    "lat_new = interp_lat(new_points).reshape(len(x_new), len(y_new))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d284bfb5-ab6e-4180-ae42-94fcc23dea7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m start_day, num_days \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5480\u001b[39m, \u001b[38;5;241m5170\u001b[39m     \u001b[38;5;66;03m# last valid day 10650 (10641 excluding the small end file)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/srv/scratch/z5297792/Chapter2/Eddy_Detection_Data/ROMS_velocity_dic_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_day\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_day\u001b[38;5;241m+\u001b[39mnum_days\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 52\u001b[0m     ROMS_velocity_dic \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "def interpolate_uv(u, v, x_grid, y_grid, X_new, Y_new, angle):\n",
    "    u_east = np.where(np.abs(u) > 1e30, np.nan, u).astype(float)\n",
    "    v_north = np.where(np.abs(v) > 1e30, np.nan, v).astype(float)\n",
    "\n",
    "    u_rot = v_north * np.sin(angle) + u_east * np.cos(angle)\n",
    "    v_rot = v_north * np.cos(angle) - u_east * np.sin(angle)\n",
    "\n",
    "    shape_new = X_new.shape\n",
    "    new_points = np.column_stack((X_new.ravel(), Y_new.ravel()))\n",
    "\n",
    "    interp_u = RegularGridInterpolator((x_grid, y_grid), u_rot,\n",
    "                                       method='linear', bounds_error=False, fill_value=np.nan)\n",
    "    interp_v = RegularGridInterpolator((x_grid, y_grid), v_rot,\n",
    "                                       method='linear', bounds_error=False, fill_value=np.nan)\n",
    "\n",
    "    u_new = interp_u(new_points).reshape(shape_new)\n",
    "    v_new = interp_v(new_points).reshape(shape_new)\n",
    "\n",
    "    return u_new, v_new\n",
    "\n",
    "def create_velocity_dic(start_day, num_days, x_grid, y_grid, X_new, Y_new, angle):\n",
    "    ROMS_velocity_dic = {}\n",
    "    for day in range(start_day, start_day + num_days + 1):\n",
    "        fnumber = 1461 + ((day - 1462) // 30)*30\n",
    "        fname = f'/srv/scratch/z3533156/26year_BRAN2020/outer_avg_{fnumber:05}.nc'\n",
    "        dataset = nc.Dataset(fname)\n",
    "        u_east = np.transpose(dataset['u_eastward'][:].data, axes=(3, 2, 1, 0))[:, :, -1, :].squeeze()\n",
    "        v_north = np.transpose(dataset['v_northward'][:].data, axes=(3, 2, 1, 0))[:, :, -1, :].squeeze()\n",
    "        ocean_time = dataset.variables['ocean_time'][:].data / 86400\n",
    "        t = np.where(day==ocean_time)[0][0]\n",
    "        if t.size != 0:\n",
    "            u, v = u_east[:, :, t], v_north[:, :, t]\n",
    "            u_new, v_new = interpolate_uv(u, v, x_grid, y_grid, X_new, Y_new, angle)\n",
    "            ROMS_velocity_dic[day] = {'u': u_new, 'v': v_new, 'fname': fname, 't': t}\n",
    "        if day % 20 == 0:\n",
    "            print(day)\n",
    "    return ROMS_velocity_dic\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "start_day, num_days = 5480, 5170     # last valid day 10650 (10641 excluding the small end file)\n",
    "ROMS_velocity_dic = create_velocity_dic(start_day, num_days, x_grid, y_grid, X_new, Y_new, angle)\n",
    "\n",
    "with open(f\"/srv/scratch/z5297792/Chapter2/Eddy_Detection_Data/ROMS_velocity_dic_{start_day}_{start_day+num_days}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ROMS_velocity_dic, f)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "\n",
    "# start_day, num_days = 5480, 5170     # last valid day 10650 (10641 excluding the small end file)\n",
    "# with open(f\"/srv/scratch/z5297792/Chapter2/Eddy_Detection_Data/ROMS_velocity_dic_{start_day}_{start_day+num_days}.pkl\", \"rb\") as f:\n",
    "#     ROMS_velocity_dic = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00737785-8ca5-4636-9cb1-c8565ad07a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ROMS_velocity_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n\u001b[1;32m     34\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 36\u001b[0m df_nenc \u001b[38;5;241m=\u001b[39m build_nenc_dataframe(\u001b[43mROMS_velocity_dic\u001b[49m, X_new, Y_new, lon_new, lat_new) \u001b[38;5;66;03m# bit over 4hrs\u001b[39;00m\n\u001b[1;32m     38\u001b[0m df_nenc\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/srv/scratch/z5297792/Chapter2/Eddy_Detection_Data/df_nenc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_day\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_day\u001b[38;5;241m+\u001b[39mnum_days\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ROMS_velocity_dic' is not defined"
     ]
    }
   ],
   "source": [
    "def build_nenc_dataframe(ROMS_velocity_dic, X_new, Y_new, lon_new, lat_new):\n",
    "    rows = []\n",
    "    for day, data in ROMS_velocity_dic.items():\n",
    "        u0, v0 = data['u'], data['v']\n",
    "        # nencioli returns a tuple; take index 2 for neddy\n",
    "        neddy = nencioli(u0.T, v0.T, X_new.T, Y_new.T, 4, 3)[2]\n",
    "        # Sort so that the highest second-column value comes first\n",
    "        neddy = neddy[neddy[:, 1].argsort()[::-1]]\n",
    "        \n",
    "        for idx, (nxc0, nyc0, cyc_indicator) in enumerate(neddy):\n",
    "            cyc_value = 'CE' if cyc_indicator == 1 else 'AE'\n",
    "            nic_idx, njc_idx = np.where((X_new == nxc0) & (Y_new == nyc0))\n",
    "            if nic_idx.size:\n",
    "                nic0, njc0 = nic_idx[0], njc_idx[0]\n",
    "            else:\n",
    "                nic0, njc0 = np.nan, np.nan\n",
    "            \n",
    "            rows.append({\n",
    "                'Eddy': idx,\n",
    "                'Day': day,\n",
    "                'Cyc': cyc_value,\n",
    "                'nLon': lon_new[nic0, njc0],\n",
    "                'nLat': lat_new[nic0, njc0],\n",
    "                'nxc': nxc0,\n",
    "                'nyc': nyc0,\n",
    "                'nic': nic0,\n",
    "                'njc': njc0\n",
    "            })\n",
    "        if day % 20 == 0:\n",
    "            print(day)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "df_nenc = build_nenc_dataframe(ROMS_velocity_dic, X_new, Y_new, lon_new, lat_new) # bit over 4hrs\n",
    "\n",
    "df_nenc.to_pickle(f\"/srv/scratch/z5297792/Chapter2/Eddy_Detection_Data/df_nenc_{start_day}_{start_day+num_days}.pkl\")\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168478c0-673a-4743-aed1-65b6e9ef7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nenc_dataframe(df_nenc, ROMS_velocity_dic, X_new, Y_new, r=30):\n",
    "\n",
    "    # DOPIOE wont work if too close to boundary\n",
    "    x_new = X_new[:, 0]\n",
    "    y_new = Y_new[0, :]\n",
    "    dx = np.max(np.diff(x_new))  # spacing in x-direction\n",
    "    dy = np.max(np.diff(y_new))  # spacing in y-direction\n",
    "    cell_size = np.max([dx, dy])        # average cell size in Euclidean units\n",
    "    margin = int(np.ceil(r / cell_size))    \n",
    "\n",
    "    df_data = df_nenc.copy()\n",
    "    for day in df_data['Day'].unique():\n",
    "        for e in df_data[df_data['Day'] == day]['Eddy'].unique():\n",
    "            # Get eddy location from the first row for this day/eddy combination.\n",
    "            row = df_data[(df_data['Day'] == day) & (df_data['Eddy'] == e)].iloc[0]\n",
    "            nxc, nyc, cyc = row['nxc'], row['nyc'], row['Cyc']\n",
    "\n",
    "            R_grid = np.hypot(nxc - X_new, nyc - Y_new)\n",
    "            ic, jc = map(int, np.unravel_index(np.argmin(R_grid), R_grid.shape))\n",
    "\n",
    "            if (ic < margin or ic >= X_new.shape[0] - margin or\n",
    "                jc < margin or jc >= X_new.shape[1] - margin):\n",
    "                xc, yc, w, Q, Rc, psi0, Ro = np.nan, np.nan, np.nan, np.array([[np.nan, np.nan],\n",
    "                                                           [np.nan, np.nan]]), np.nan, np.nan, np.nan\n",
    "            else:\n",
    "                ut, vt = ROMS_velocity_dic[day]['u'], ROMS_velocity_dic[day]['v']\n",
    "    \n",
    "                # horizontal transect (constant y = y[jc])\n",
    "                x_mask = np.abs(x_new - nxc) < r\n",
    "                x1 = x_new[x_mask]\n",
    "                y1 = np.full_like(x1, y_new[jc])\n",
    "                u1 = ut[x_mask, jc]\n",
    "                v1 = vt[x_mask, jc]\n",
    "            \n",
    "                # vertical transect (constant x = x[ic])\n",
    "                y_mask = np.abs(y_new - nyc) < r\n",
    "                y2 = y_new[y_mask]\n",
    "                x2 = np.full_like(y2, x_new[ic])\n",
    "                u2 = ut[ic, y_mask]\n",
    "                v2 = vt[ic, y_mask]\n",
    "    \n",
    "                xc, yc, w, Q, _, psi0, _ = dopioe(x1, y1, u1, v1, x2, y2, u2, v2)\n",
    "    \n",
    "                cyc_DOPIOE = 'CE' if w < 0 else 'AE'\n",
    "    \n",
    "                if (cyc_DOPIOE != cyc) or (np.hypot(nxc - xc, nyc - yc) > 50):\n",
    "                    xc, yc, w, Q, Rc, psi0, Ro = np.nan, np.nan, np.nan, np.array([[np.nan, np.nan],\n",
    "                                                               [np.nan, np.nan]]), np.nan, np.nan, np.nan\n",
    "                else:\n",
    "                    w *= 1e-3 # to s^-1\n",
    "                    Ro = rossby_number(w, yc)\n",
    "        \n",
    "                    radii = find_directional_radii(ut, vt, X_new, Y_new, xc, yc, calc_tang_vel)\n",
    "                    Rc = np.mean([radii['up'], radii['right'], radii['down'], radii['left']])\n",
    "                \n",
    "            # Update DataFrame for this day/eddy.\n",
    "            update_mask = (df_data['Day'] == day) & (df_data['Eddy'] == e)\n",
    "            df_data.loc[update_mask, 'xc'] = xc\n",
    "            df_data.loc[update_mask, 'yc'] = yc\n",
    "            df_data.loc[update_mask, 'w'] = w\n",
    "            df_data.loc[update_mask, 'Q11'] = Q[0, 0]\n",
    "            df_data.loc[update_mask, 'Q12'] = Q[1, 0]\n",
    "            df_data.loc[update_mask, 'Q22'] = Q[1, 1]\n",
    "            df_data.loc[update_mask, 'Rc'] = Rc\n",
    "            df_data.loc[update_mask, 'psi0'] = psi0\n",
    "            df_data.loc[update_mask, 'Ro'] = Ro\n",
    "\n",
    "        if day % 20 == 0:\n",
    "            print(day)\n",
    "\n",
    "    return df_data\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "df_data = update_nenc_dataframe(df_nenc, ROMS_velocity_dic, X_new, Y_new)\n",
    "\n",
    "del df_nenc, ROMS_velocity_dic\n",
    "\n",
    "df_data.to_pickle(f\"/srv/scratch/z5297792/Chapter2/Eddy_Detection_Data/df_data_{start_day}_{start_day+num_days}.pkl\") # 2 hrs\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94641451-78dd-4479-b6df-dd0e30295fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51053b-50c1-4577-a10f-536988023be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733660d4-eeb7-4868-bee6-464eea4df17d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
