{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd191a7f-a5b0-47fe-9403-bc957878889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "import netCDF4 as nc\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc6da51-cc38-4afa-a539-d07947cb11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day, end_day = 1462, 10650\n",
    "df_data = pd.read_pickle(f\"/srv/scratch/z5297792/Chapter2/df_data_{start_day}_{end_day}.pkl\")\n",
    "df_data = df_data.dropna().copy() # If ESPRA didnt work then we dont have vorticity, which is required for tracking\n",
    "\n",
    "df_data = df_data[(df_data['Day']>=start_day)&(df_data['Day']<=end_day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df2dd10-d21e-4e76-a019-3a14f52f0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tracking(df_data, VORT_WEIGHT=15000, R_THRESH=30):\n",
    "\n",
    "#     df_data = df_data.copy()\n",
    "#     # Initialize IDs: set first day IDs equal to their Eddy values.\n",
    "#     min_day = df_data['Day'].min()\n",
    "#     df_data['ID'] = -1\n",
    "#     df_data.loc[df_data['Day'] == min_day, 'ID'] = np.arange(len(df_data.loc[df_data['Day'] == min_day, 'ID'])) # for the initial dataset\n",
    "#     df_data['ID'] = df_data['ID'].astype('Int64')\n",
    "#     next_num = df_data['ID'].max() + 1\n",
    "\n",
    "#     R_df = pd.DataFrame(columns=['D_diff', 'W_diff', 'R'])\n",
    "\n",
    "#     # Loop through days starting from min_day+1 to max_day.\n",
    "#     for day in range(min_day + 1, df_data['Day'].max() + 1):\n",
    "#         pres_day = df_data[df_data['Day'] == day].copy()\n",
    "#         pres_day = pres_day[~np.isnan(pres_day['x0'])]\n",
    "#         for e_pres in pres_day['Eddy'].unique():\n",
    "#             pres_eddy = pres_day[pres_day['Eddy'] == e_pres].iloc[0]\n",
    "#             assigned = False\n",
    "#             # Look back up to 4 days.\n",
    "#             for delta in range(1, 5):\n",
    "#                 candidate_day = day - delta\n",
    "#                 if candidate_day < 0:\n",
    "#                     continue\n",
    "#                 candidate_prev = df_data[df_data['Day'] == candidate_day].copy()\n",
    "#                 candidate_prev = candidate_prev[~np.isnan(candidate_prev['x0'])]\n",
    "#                 for e_prev in candidate_prev['Eddy'].unique():\n",
    "#                     prev_eddy = candidate_prev[candidate_prev['Eddy'] == e_prev].iloc[0]\n",
    "#                     R = np.sqrt(\n",
    "#                         (pres_eddy['x0'] - prev_eddy['x0'])**2 +\n",
    "#                         (pres_eddy['y0'] - prev_eddy['y0'])**2 +\n",
    "#                         VORT_WEIGHT * (pres_eddy['w'] - prev_eddy['w'])**2    # IF ESPRA DIDNT WORK USE NENCIOLI!!\n",
    "#                     )\n",
    "#                     D_diff = np.hypot(pres_eddy['x0'] - prev_eddy['x0'], pres_eddy['y0'] - prev_eddy['y0'])\n",
    "#                     W_diff = np.abs(pres_eddy['w'] - prev_eddy['w'])\n",
    "#                     R_df.loc[len(R_df)] = {'D_diff': D_diff, 'W_diff': W_diff, 'R': R}\n",
    "#                     if R < R_THRESH and (pres_eddy['Cyc'] == prev_eddy['Cyc']) and not (pres_day['ID'] == prev_eddy['ID']).any():\n",
    "#                         df_data.loc[(df_data['Day'] == day) & (df_data['Eddy'] == e_pres), 'ID'] = prev_eddy['ID']\n",
    "#                         assigned = True\n",
    "#                         break\n",
    "#                 if assigned:\n",
    "#                     break\n",
    "#             if not assigned:\n",
    "#                 df_data.loc[(df_data['Day'] == day) & (df_data['Eddy'] == e_pres), 'ID'] = next_num\n",
    "#                 next_num += 1\n",
    "\n",
    "#         if day % 20 == 0:\n",
    "#             print(day)\n",
    "\n",
    "#     df_data['next_num'] = next_num\n",
    "                \n",
    "#     return df_data, R_df\n",
    "\n",
    "# tic = time.perf_counter()\n",
    "\n",
    "# df_eddies, R_df = tracking(df_data)\n",
    "\n",
    "# toc = time.perf_counter()\n",
    "# print(f\"Elapsed time: {toc - tic:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99103ed8-647c-4e9b-8afe-abec49e3a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tracking(df_data, start_ID, next_num, VORT_WEIGHT=15000, R_THRESH=30):\n",
    "\n",
    "#     tic = time.perf_counter()\n",
    "\n",
    "#     # Work on a copy so as not to modify the original DataFrame.\n",
    "#     df_data = df_data.copy()\n",
    "    \n",
    "#     # Initialize IDs: set first day IDs equal to start_ID.\n",
    "#     min_day = df_data['Day'].min()\n",
    "#     df_data['ID'] = -1\n",
    "#     df_data.loc[df_data['Day'] == min_day, 'ID'] = start_ID  # for the initial dataset\n",
    "#     df_data['ID'] = df_data['ID'].astype('Int64')\n",
    "\n",
    "#     # Precompute a dictionary mapping each day to the indices of rows where 'x0' is not NaN.\n",
    "#     unique_days = sorted(df_data['Day'].unique())\n",
    "#     day_dict = {\n",
    "#         d: df_data.index[(df_data['Day'] == d) & (~df_data['x0'].isna())]\n",
    "#         for d in unique_days\n",
    "#     }\n",
    "\n",
    "#     # Use a list to collect R values rather than appending row-by-row to a DataFrame.\n",
    "#     df_R_rows = []\n",
    "    \n",
    "#     max_day = df_data['Day'].max()\n",
    "#     for day in range(min_day + 1, max_day + 1):\n",
    "#         # Skip this day if no valid rows exist.\n",
    "#         if day not in day_dict or len(day_dict[day]) == 0:\n",
    "#             continue\n",
    "\n",
    "#         # Get all rows for the current day with valid x0.\n",
    "#         pres_day = df_data.loc[day_dict[day]]\n",
    "#         unique_eddies = pres_day['Eddy'].unique()\n",
    "\n",
    "#         for e_pres in unique_eddies:\n",
    "#             # Get the first occurrence for this eddy.\n",
    "#             pres_eddy = pres_day[pres_day['Eddy'] == e_pres].iloc[0]\n",
    "#             assigned = False\n",
    "\n",
    "#             # Look back up to 4 days.\n",
    "#             for delta in range(1, 5):\n",
    "#                 candidate_day = day - delta\n",
    "#                 if candidate_day < min_day:\n",
    "#                     continue\n",
    "#                 if candidate_day not in day_dict or len(day_dict[candidate_day]) == 0:\n",
    "#                     continue\n",
    "\n",
    "#                 # Get candidate previous day rows.\n",
    "#                 candidate_prev = df_data.loc[day_dict[candidate_day]]\n",
    "#                 # Group by 'Eddy' and take the first row for each unique eddy while preserving original order.\n",
    "#                 candidate_group = candidate_prev.groupby('Eddy', as_index=False, sort=False).first()\n",
    "\n",
    "#                 for _, prev_eddy in candidate_group.iterrows():\n",
    "#                     # Compute differences and R value.\n",
    "#                     dx = pres_eddy['x0'] - prev_eddy['x0']\n",
    "#                     dy = pres_eddy['y0'] - prev_eddy['y0']\n",
    "#                     dw = pres_eddy['w'] - prev_eddy['w']\n",
    "#                     R = np.sqrt(dx ** 2 + dy ** 2 + VORT_WEIGHT * (dw ** 2))\n",
    "#                     D_diff = np.hypot(dx, dy)\n",
    "#                     W_diff = np.abs(dw)\n",
    "#                     df_R_rows.append({'D_diff': D_diff, 'W_diff': W_diff, 'R': R})\n",
    "\n",
    "#                     # Check if current candidate meets the criteria.\n",
    "#                     if (R < R_THRESH) and (pres_eddy['Cyc'] == prev_eddy['Cyc']) and not (pres_day['ID'] == prev_eddy['ID']).any():\n",
    "#                         df_data.loc[(df_data['Day'] == day) & (df_data['Eddy'] == e_pres), 'ID'] = prev_eddy['ID']\n",
    "#                         assigned = True\n",
    "#                         break\n",
    "\n",
    "#                 if assigned:\n",
    "#                     break\n",
    "\n",
    "#             if not assigned:\n",
    "#                 df_data.loc[(df_data['Day'] == day) & (df_data['Eddy'] == e_pres), 'ID'] = next_num\n",
    "#                 next_num += 1\n",
    "\n",
    "#         # Periodically print progress every 10 days.\n",
    "#         if day % 200 == 0:\n",
    "#             toc = time.perf_counter()\n",
    "#             print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "#             print(day)\n",
    "\n",
    "#     # Convert the accumulated R values list to a DataFrame.\n",
    "#     df_R = pd.DataFrame(df_R_rows)\n",
    "#     df_data['next_num'] = next_num\n",
    "\n",
    "#     return df_data, df_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286f9d96-d6a1-4cce-abed-545c42a59464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking(df_data, start_ID, next_num, VORT_WEIGHT=15000, R_THRESH=50):\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    df_data = df_data.copy()\n",
    "    min_day = df_data['Day'].min()\n",
    "    df_data['ID'] = -1\n",
    "    df_data.loc[df_data['Day'] == min_day, 'ID'] = start_ID\n",
    "    df_data['ID'] = df_data['ID'].astype('Int64')\n",
    "\n",
    "    unique_days = sorted(df_data['Day'].unique())\n",
    "    day_dict = {\n",
    "        d: df_data.index[(df_data['Day'] == d) & (~df_data['x0'].isna())]\n",
    "        for d in unique_days\n",
    "    }\n",
    "\n",
    "    df_R_rows = []\n",
    "    max_day = df_data['Day'].max()\n",
    "\n",
    "    for day in range(min_day + 1, max_day + 1):\n",
    "        if day not in day_dict or len(day_dict[day]) == 0:\n",
    "            continue\n",
    "\n",
    "        pres_day = df_data.loc[day_dict[day]].copy()\n",
    "        unique_eddies = pres_day['Eddy'].unique()\n",
    "        assigned_IDs = set()  ### MODIFIED ### track assigned IDs per day\n",
    "\n",
    "        for e_pres in unique_eddies:\n",
    "            pres_eddy = pres_day[pres_day['Eddy'] == e_pres].iloc[0]\n",
    "            best_match = None\n",
    "            best_R = np.inf\n",
    "\n",
    "            for delta in range(1, 5):\n",
    "                candidate_day = day - delta\n",
    "                if candidate_day < min_day:\n",
    "                    continue\n",
    "                if candidate_day not in day_dict or len(day_dict[candidate_day]) == 0:\n",
    "                    continue\n",
    "\n",
    "                candidate_prev = df_data.loc[day_dict[candidate_day]]\n",
    "                candidate_group = candidate_prev.groupby('Eddy', as_index=False, sort=False).first()\n",
    "\n",
    "                for _, prev_eddy in candidate_group.iterrows():\n",
    "                    dx = pres_eddy['x0'] - prev_eddy['x0']\n",
    "                    dy = pres_eddy['y0'] - prev_eddy['y0']\n",
    "                    dw = pres_eddy['w'] - prev_eddy['w']\n",
    "                    R = np.sqrt(dx ** 2 + dy ** 2 + VORT_WEIGHT * (dw ** 2))\n",
    "                    D_diff = np.hypot(dx, dy)\n",
    "                    W_diff = np.abs(dw)\n",
    "\n",
    "                    df_R_rows.append({'D_diff': D_diff, 'W_diff': W_diff, 'R': R})\n",
    "\n",
    "                    # Check match criteria\n",
    "                    if (\n",
    "                        R < R_THRESH\n",
    "                        and pres_eddy['Cyc'] == prev_eddy['Cyc']\n",
    "                        and prev_eddy['ID'] not in assigned_IDs  ### MODIFIED ###\n",
    "                        and not pd.isna(prev_eddy['ID'])\n",
    "                    ):\n",
    "                        if R < best_R:\n",
    "                            best_match = prev_eddy\n",
    "                            best_R = R\n",
    "\n",
    "            if best_match is not None:\n",
    "                matched_id = best_match['ID']\n",
    "                df_data.loc[(df_data['Day'] == day) & (df_data['Eddy'] == e_pres), 'ID'] = matched_id\n",
    "                assigned_IDs.add(matched_id)  ### MODIFIED ###\n",
    "            else:\n",
    "                df_data.loc[(df_data['Day'] == day) & (df_data['Eddy'] == e_pres), 'ID'] = next_num\n",
    "                assigned_IDs.add(next_num)  ### MODIFIED ###\n",
    "                next_num += 1\n",
    "\n",
    "        if day % 200 == 0:\n",
    "            toc = time.perf_counter()\n",
    "            print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "            print(day)\n",
    "\n",
    "    df_R = pd.DataFrame(df_R_rows)\n",
    "    df_data['next_num'] = next_num\n",
    "\n",
    "    # Final check for duplicates\n",
    "    assert not df_data.duplicated(subset=['ID', 'Day']).any(), \"Duplicate (ID, Day) pairs found!\"\n",
    "\n",
    "    return df_data, df_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9994bd-aca9-42d8-8024-8cc821a8372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 83.7444 seconds\n",
      "1600\n",
      "Elapsed time: 273.4623 seconds\n",
      "1800\n",
      "Elapsed time: 394.5894 seconds\n",
      "2000\n",
      "Elapsed time: 546.0512 seconds\n",
      "2200\n",
      "Elapsed time: 665.3679 seconds\n",
      "2400\n",
      "Elapsed time: 793.1496 seconds\n",
      "2600\n",
      "Elapsed time: 930.6238 seconds\n",
      "2800\n",
      "Elapsed time: 1045.6990 seconds\n",
      "3000\n",
      "Elapsed time: 1171.1432 seconds\n",
      "3200\n",
      "Elapsed time: 1267.7612 seconds\n",
      "3400\n",
      "Elapsed time: 1406.7338 seconds\n",
      "3600\n",
      "Elapsed time: 1515.1264 seconds\n",
      "3800\n",
      "Elapsed time: 1673.9326 seconds\n",
      "4000\n",
      "Elapsed time: 1795.2377 seconds\n",
      "4200\n",
      "Elapsed time: 1941.3291 seconds\n",
      "4400\n",
      "Elapsed time: 2062.5138 seconds\n",
      "4600\n",
      "Elapsed time: 2202.2407 seconds\n",
      "4800\n",
      "Elapsed time: 2356.0831 seconds\n",
      "5000\n",
      "Elapsed time: 2495.6272 seconds\n",
      "5200\n",
      "Elapsed time: 2661.6424 seconds\n",
      "5400\n",
      "Elapsed time: 2784.9377 seconds\n",
      "5600\n",
      "Elapsed time: 2956.3059 seconds\n",
      "5800\n",
      "Elapsed time: 3071.7924 seconds\n",
      "6000\n",
      "Elapsed time: 3274.2199 seconds\n",
      "6200\n",
      "Elapsed time: 3413.3732 seconds\n",
      "6400\n",
      "Elapsed time: 3569.4521 seconds\n",
      "6600\n",
      "Elapsed time: 3723.1193 seconds\n",
      "6800\n",
      "Elapsed time: 3858.9927 seconds\n",
      "7000\n",
      "Elapsed time: 3996.9737 seconds\n",
      "7200\n",
      "Elapsed time: 4100.2988 seconds\n",
      "7400\n",
      "Elapsed time: 4225.6393 seconds\n",
      "7600\n",
      "Elapsed time: 4325.8113 seconds\n",
      "7800\n",
      "Elapsed time: 4496.6243 seconds\n",
      "8000\n",
      "Elapsed time: 4599.4865 seconds\n",
      "8200\n",
      "Elapsed time: 4760.9374 seconds\n",
      "8400\n",
      "Elapsed time: 4862.1488 seconds\n",
      "8600\n",
      "Elapsed time: 5002.3921 seconds\n",
      "8800\n",
      "Elapsed time: 5125.6810 seconds\n",
      "9000\n",
      "Elapsed time: 5240.5238 seconds\n",
      "9200\n",
      "Elapsed time: 5387.6949 seconds\n",
      "9400\n",
      "Elapsed time: 5510.0048 seconds\n",
      "9600\n",
      "Elapsed time: 5638.7412 seconds\n",
      "9800\n",
      "Elapsed time: 5730.7969 seconds\n",
      "10000\n",
      "Elapsed time: 5867.8991 seconds\n",
      "10200\n",
      "Elapsed time: 5974.3091 seconds\n",
      "10400\n",
      "Elapsed time: 6110.7636 seconds\n",
      "10600\n"
     ]
    }
   ],
   "source": [
    "start_ID = np.arange(len(df_data[df_data['Day']==df_data['Day'].min()]))\n",
    "next_num = np.max(start_ID) + 1\n",
    "\n",
    "df_eddies, df_R = tracking(df_data, start_ID, next_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd51053b-50c1-4577-a10f-536988023be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eddies.to_pickle(f\"/srv/scratch/z5297792/Chapter2/df_eddies_{start_day}_{end_day}.pkl\")\n",
    "df_R.to_pickle(f\"/srv/scratch/z5297792/Chapter2/df_R_{start_day}_{end_day}.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
