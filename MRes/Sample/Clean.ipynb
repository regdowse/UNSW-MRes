{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d343c424-271c-4bd1-8b46-227c8fdd6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ROMS_26yr_daydic.pkl', 'rb') as file:\n",
    "    daydic = pickle.load(file)\n",
    "\n",
    "with open('ROMS_26yr_eddies.pkl', 'rb') as file:\n",
    "    eddies = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc335b58-7db2-425b-8d5b-6bb302cb9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "fname = '/srv/scratch/z3533156/26year_BRAN2020/outer_avg_01461.nc'\n",
    "dataset = nc.Dataset(fname)\n",
    "lon_rho  = dataset.variables['lon_rho'][:]\n",
    "lon_rho = np.transpose(lon_rho, axes=(1, 0))\n",
    "lat_rho  = dataset.variables['lat_rho'][:]\n",
    "lat_rho = np.transpose(lat_rho, axes=(1, 0))\n",
    "f  = dataset.variables['f'][:]\n",
    "f = np.transpose(f, axes=(1, 0))\n",
    "h = dataset.variables['h'][:]\n",
    "h = np.transpose(h, axes=(1, 0))\n",
    "z_r = np.load('/home/z5297792/UNSW-MRes/MRes/z_r/z_r.npy')\n",
    "z_r = np.transpose(z_r, (1, 2, 0))\n",
    "temp_ave = np.load('/srv/scratch/z5297792/Climatology/temp_ave.npy')\n",
    "CurSpeed_ave = np.load('/srv/scratch/z5297792/Climatology/CurSpeed_ave.npy')\n",
    "\n",
    "import re\n",
    "def extract_number(s):\n",
    "    match = re.search(r'\\d+', s)\n",
    "    return int(match.group()) if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a3109e-64f9-4d71-abcc-aabafaf1652b",
   "metadata": {},
   "source": [
    "#### Flow Like Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a00a31-dd82-4c44-a98a-ad7287dde40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "with open('/srv/scratch/z5297792/Sample/frontier_sample_data.pkl', 'rb') as file:\n",
    "    frontier_sample_data = pickle.load(file)\n",
    "the_frontier_eddies = list(frontier_sample_data.keys())\n",
    "# Depths will be limited to COW depths\n",
    "d_df = pd.DataFrame(columns=['T' + str(t) for t in range(30)])\n",
    "for eddy in the_frontier_eddies:\n",
    "    row = []\n",
    "    for t in range(30):\n",
    "        df = frontier_sample_data[eddy]['T' + str(t)]['COW']['x']\n",
    "        row.append(df.isna().idxmax() if df.isna().any() else len(df))\n",
    "    d_df.loc[eddy] = row\n",
    "\n",
    "eddy = the_frontier_eddies[2]\n",
    "\n",
    "sub_data = {}\n",
    "\n",
    "for t in range(30):\n",
    "    \n",
    "    method = 'VG'\n",
    "    sub_data['T'+str(t)] = {}\n",
    "    \n",
    "    df = frontier_sample_data[eddy]['T'+str(t)][method].iloc[:d_df.loc[eddy]['T'+str(t)]]\n",
    "    df = df.drop('TD', axis=1)\n",
    "    \n",
    "    # Interpolate to Density intervals\n",
    "    rho = frontier_sample_data[eddy]['T'+str(t)]['rho']\n",
    "    X, Y = np.meshgrid(frontier_sample_data[eddy]['T'+str(t)]['x'],\n",
    "                       frontier_sample_data[eddy]['T'+str(t)]['y'])\n",
    "    points = np.column_stack((X.ravel(), Y.ravel()))\n",
    "    rhoc = []\n",
    "    for k, (xc, yc) in enumerate(zip(df['x'], df['y'])):\n",
    "        values = rho[:, :, k].ravel()\n",
    "        target_point = np.array([[xc, yc]])\n",
    "        rhoc.append(griddata(points, values, target_point, method='linear')[0])\n",
    "    RHO_INT = 0.05\n",
    "    new_rho = np.arange(np.floor(np.nanmin(rhoc) / RHO_INT) * RHO_INT,\n",
    "                        np.ceil(np.nanmax(rhoc) / RHO_INT) * RHO_INT + RHO_INT,\n",
    "                        RHO_INT)\n",
    "    rho_data = pd.DataFrame({\n",
    "        'x': np.interp(new_rho, rhoc, df['x']),\n",
    "        'y': np.interp(new_rho, rhoc, df['y']),\n",
    "        'Depth': np.interp(new_rho, rhoc, df['Depth']),\n",
    "        'rho': new_rho\n",
    "    })\n",
    "    # TD_DENSITY = 26\n",
    "    # x0 = rho_data.loc[np.isclose(rho_data['rho'], TD_DENSITY)].iloc[0]['x']\n",
    "    # y0 = rho_data.loc[np.isclose(rho_data['rho'], TD_DENSITY)].iloc[0]['y']\n",
    "    x0 = rho_data.iloc[0]['x']\n",
    "    y0 = rho_data.iloc[0]['y']\n",
    "    rho_data['x'] = rho_data['x'] - x0\n",
    "    rho_data['y'] = rho_data['y'] - y0\n",
    "    rho_data['TD'] = np.hypot(rho_data['x'], rho_data['y'])\n",
    "    \n",
    "    # Interpolate to Depth intervals\n",
    "    DEPTH_INT = 10\n",
    "    new_depth = np.arange(0, -np.floor(df['Depth'].min()/DEPTH_INT) * DEPTH_INT + DEPTH_INT, DEPTH_INT)\n",
    "    depth_data = pd.DataFrame({\n",
    "        'x': np.interp(new_depth, -df['Depth'], df['x']),\n",
    "        'y': np.interp(new_depth, -df['Depth'], df['y']),\n",
    "        'Depth': -new_depth,\n",
    "        'rho': np.interp(new_depth, -df['Depth'], rhoc),\n",
    "    })\n",
    "    # TD_DEPTH = -150\n",
    "    # x0 = depth_data.loc[np.isclose(depth_data['Depth'], TD_DEPTH)].iloc[0]['x']\n",
    "    # y0 = depth_data.loc[np.isclose(depth_data['Depth'], TD_DEPTH)].iloc[0]['y']\n",
    "    x0 = depth_data.iloc[0]['x']\n",
    "    y0 = depth_data.iloc[0]['y']\n",
    "    depth_data['x'] = depth_data['x'] - x0\n",
    "    depth_data['y'] = depth_data['y'] - y0\n",
    "    depth_data['TD'] = np.hypot(depth_data['x'], depth_data['y'])\n",
    "\n",
    "    sub_data['T'+str(t)]['rho_data'] = rho_data\n",
    "    sub_data['T'+str(t)]['depth_data'] = depth_data\n",
    "    print(t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3773f77-dfb4-4a8c-9c5a-36ad604df5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 10))\n",
    "# Plot depth data\n",
    "ax1.plot(depth_data['TD']/1000, depth_data['Depth'], 'b-')\n",
    "ax1.set_xlabel('TD')\n",
    "ax1.set_ylabel('Depth', color='b')\n",
    "\n",
    "# Create a second y-axis for density data\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(rho_data['TD']/1000, -rho_data['rho'], 'r-')\n",
    "ax2.set_ylabel('Density', color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784d4f3-4126-416b-8bf7-3df06f783c43",
   "metadata": {},
   "source": [
    "### Best Shift with rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716786b-ed62-47a6-8f32-7c5e74f7eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "medium = 'TD'\n",
    "dfs_x = []\n",
    "dfs_y = []\n",
    "dfs_TD = []\n",
    "for t in range(30):\n",
    "    rho_data = sub_data['T'+str(t)]['rho_data'][['rho', 'x']]\n",
    "    rho_data.columns = ['rho', 'x'+str(t)]\n",
    "    dfs_x.append(rho_data.set_index('rho'))  \n",
    "\n",
    "    rho_data = sub_data['T'+str(t)]['rho_data'][['rho', 'y']]\n",
    "    rho_data.columns = ['rho', 'y'+str(t)]\n",
    "    dfs_y.append(rho_data.set_index('rho'))  \n",
    "\n",
    "    rho_data = sub_data['T'+str(t)]['rho_data'][['rho', 'TD']]\n",
    "    rho_data.columns = ['rho', 'TD'+str(t)]\n",
    "    dfs_TD.append(rho_data.set_index('rho'))  \n",
    "\n",
    "rho_df_x = pd.concat(dfs_x, axis=1) \n",
    "rho_df_y = pd.concat(dfs_y, axis=1) \n",
    "rho_df_TD = pd.concat(dfs_TD, axis=1) \n",
    "\n",
    "for col in rho_df_TD.columns:\n",
    "    plt.plot(rho_df_TD[col], -rho_df_TD.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417f371-4755-4bd5-877d-2c161d2f4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0d90ff-e1f4-41d8-8f0e-b84d31e19ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_y_xy(points, theta_deg):\n",
    "    \"\"\"Rotate points (x, y) about the y-axis by angle theta (in degrees).\"\"\"\n",
    "    theta = np.deg2rad(theta_deg)  # Convert degrees to radians\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "    xy_rotated = np.dot(points[:, :2], rotation_matrix.T)\n",
    "    return np.hstack((xy_rotated, points[:, 2:]))\n",
    "\n",
    "x0, y0 = rho_df_x['x14']/1000, rho_df_y['y14']/1000\n",
    "points0 = np.column_stack((x0, y0))\n",
    "\n",
    "shift_df = pd.DataFrame(columns=['Day', 'theta', 'i', 'j', 'rmse'])\n",
    "\n",
    "tic = time.time()\n",
    "for t in range(0, 30):\n",
    "\n",
    "    x, y = rho_df_x['x'+str(t)]/1000, rho_df_y['y'+str(t)]/1000\n",
    "    points = np.column_stack((x, y))\n",
    "\n",
    "    for theta_shift in np.arange(0, 360, 5):\n",
    "        \n",
    "        points_rotated = rotate_y_xy(points, theta_shift)\n",
    "\n",
    "        for i_shift in range(-20, 20):\n",
    "            for j_shift in range(-20, 20):\n",
    "\n",
    "                points_shifted = np.column_stack((points_rotated[:,0] + i_shift,\n",
    "                                                  points_rotated[:,1] + j_shift))\n",
    "\n",
    "\n",
    "                if not np.all(np.isnan(points_shifted - points0)):\n",
    "                    rmse = np.sqrt(np.nanmean((points_shifted - points0) ** 2))\n",
    "                else:\n",
    "                    rmse = np.nan\n",
    "                \n",
    "                shift_df.loc[len(shift_df)] = {\n",
    "                    'Day': t,\n",
    "                    'theta': theta_shift,\n",
    "                    'i': i_shift,\n",
    "                    'j': j_shift,\n",
    "                    'rmse': rmse\n",
    "                }\n",
    "    print(t)\n",
    "toc = time.time()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "\n",
    "rho_best_shift_df = pd.DataFrame()\n",
    "for t in shift_df['Day'].unique():\n",
    "    day_df = shift_df.loc[shift_df['Day'] == t]\n",
    "    if np.all(np.isnan(day_df['rmse'])):\n",
    "        rho_best_shift_df = pd.concat([rho_best_shift_df, day_df.iloc[0]]) #FIX\n",
    "    else:\n",
    "        rho_best_shift_df = pd.concat([rho_best_shift_df, day_df.loc[[day_df['rmse'].idxmin()]]])\n",
    "rho_best_shift_df\n",
    "\n",
    "with open('/srv/scratch/z5297792/Sample/rho_best_shift'+eddy+'.pkl', 'wb') as file:\n",
    "    pickle.dump(rho_best_shift_df, file)\n",
    "\n",
    "# 40 min for 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dbe436-12bb-4ca7-a440-1ee3f12c442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_best_shift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4876ce-4398-4705-814e-bae95f431da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for _, row in best_shift_df.iterrows():\n",
    "    t, theta, i, j = int(row['Day']), row['theta'], row['i'], row['j']\n",
    "\n",
    "    x, y = rho_df_x[f'x{t}']/1000, rho_df_y[f'y{t}']/1000\n",
    "    x, y = rotate_y_xy(np.column_stack((x, y)), theta).T\n",
    "    x, y = x + i, y + j\n",
    "\n",
    "    ax.plot(x, y, -rho_df_x.index)\n",
    "ax.view_init(elev=10, azim=135)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659b695-2cc1-45fb-bd02-6a167c9b6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for _, row in best_shift_df.iterrows():\n",
    "    t, theta, i, j = int(row['Day']), row['theta'], row['i'], row['j']\n",
    "\n",
    "    x, y = rho_df_x[f'x{t}']/1000, rho_df_y[f'y{t}']/1000\n",
    "\n",
    "    ax.plot(x, y, -rho_df_x.index)\n",
    "ax.view_init(elev=10, azim=135)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc871889-5d75-4639-9cf4-bca6ddd2f836",
   "metadata": {},
   "source": [
    "### Best shift with Depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903a252-5369-4a01-966b-8bbfaba75096",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "medium = 'TD'\n",
    "dfs_x = []\n",
    "dfs_y = []\n",
    "dfs_TD = []\n",
    "for t in range(30):\n",
    "    depth_data = sub_data['T'+str(t)]['depth_data'][['Depth', 'x']]\n",
    "    depth_data.columns = ['Depth', 'x'+str(t)]\n",
    "    dfs_x.append(depth_data.set_index('Depth'))  \n",
    "\n",
    "    depth_data = sub_data['T'+str(t)]['depth_data'][['Depth', 'y']]\n",
    "    depth_data.columns = ['Depth', 'y'+str(t)]\n",
    "    dfs_y.append(depth_data.set_index('Depth'))  \n",
    "\n",
    "    depth_data = sub_data['T'+str(t)]['depth_data'][['Depth', 'TD']]\n",
    "    depth_data.columns = ['Depth', 'TD'+str(t)]\n",
    "    dfs_TD.append(depth_data.set_index('Depth'))  \n",
    "\n",
    "depth_df_x = pd.concat(dfs_x, axis=1) \n",
    "depth_df_y = pd.concat(dfs_y, axis=1) \n",
    "depth_df_TD = pd.concat(dfs_TD, axis=1) \n",
    "\n",
    "for col in depth_df_TD.columns:\n",
    "    plt.plot(depth_df_TD[col], depth_df_TD.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c367fcf-be21-4cad-8ea4-57ea5f55a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d30d90-6c8e-4ab3-a2e7-59c81816a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_y_xy(points, theta_deg):\n",
    "    \"\"\"Rotate points (x, y) about the y-axis by angle theta (in degrees).\"\"\"\n",
    "    theta = np.deg2rad(theta_deg)  # Convert degrees to radians\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "    xy_rotated = np.dot(points[:, :2], rotation_matrix.T)\n",
    "    return np.hstack((xy_rotated, points[:, 2:]))\n",
    "\n",
    "x0, y0 = depth_df_x['x14']/1000, depth_df_y['y14']/1000\n",
    "points0 = np.column_stack((x0, y0))\n",
    "\n",
    "shift_df = pd.DataFrame(columns=['Day', 'theta', 'i', 'j', 'rmse'])\n",
    "\n",
    "tic = time.time()\n",
    "for t in range(0, 25):\n",
    "\n",
    "    x, y = depth_df_x['x'+str(t)]/1000, depth_df_y['y'+str(t)]/1000\n",
    "    points = np.column_stack((x, y))\n",
    "\n",
    "    for theta_shift in np.arange(0, 360, 30):\n",
    "        \n",
    "        points_rotated = rotate_y_xy(points, theta_shift)\n",
    "\n",
    "        for i_shift in range(15, 15):\n",
    "            for j_shift in range(-15, 15):\n",
    "\n",
    "                points_shifted = np.column_stack((points_rotated[:,0] + i_shift,\n",
    "                                                  points_rotated[:,1] + j_shift))\n",
    "\n",
    "                if not np.all(np.isnan(points_shifted - points0)):\n",
    "                    rmse = np.sqrt(np.nanmean((points_shifted - points0) ** 2))\n",
    "                else:\n",
    "                    rmse = np.nan\n",
    "                \n",
    "                shift_df.loc[len(shift_df)] = {\n",
    "                    'Day': t,\n",
    "                    'theta': theta_shift,\n",
    "                    'i': i_shift,\n",
    "                    'j': j_shift,\n",
    "                    'rmse': rmse\n",
    "                }\n",
    "    print(t)\n",
    "toc = time.time()\n",
    "print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "\n",
    "depth_best_shift_df = pd.DataFrame()\n",
    "for t in shift_df['Day'].unique():\n",
    "    day_df = shift_df.loc[shift_df['Day'] == t]\n",
    "    if np.all(np.isnan(day_df['rmse'])):\n",
    "        depth_best_shift_df = pd.concat([depth_best_shift_df, day_df.iloc[0]])\n",
    "    else:\n",
    "        depth_best_shift_df = pd.concat([depth_best_shift_df, day_df.loc[[day_df['rmse'].idxmin()]]])\n",
    "depth_best_shift_df\n",
    "\n",
    "with open('/srv/scratch/z5297792/Sample/depth_best_shift'+eddy+'.pkl', 'wb') as file:\n",
    "    pickle.dump(depth_best_shift_df, file)\n",
    "# 40 min for 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965ed5a-5c8f-4136-8c37-8c19272762ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for _, row in best_shift_df.iterrows():\n",
    "    t, theta, i, j = int(row['Day']), row['theta'], row['i'], row['j']\n",
    "\n",
    "    x, y = depth_df_x[f'x{t}']/1000, depth_df_y[f'y{t}']/1000\n",
    "    x, y = rotate_y_xy(np.column_stack((x, y)), theta).T\n",
    "    x, y = x + i, y + j\n",
    "\n",
    "    ax.plot(x, y, depth_df_x.index)\n",
    "ax.view_init(elev=10, azim=135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecc6bd-96ca-4490-b2bc-2708c1b9dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for _, row in best_shift_df.iterrows():\n",
    "    t, theta, i, j = int(row['Day']), row['theta'], row['i'], row['j']\n",
    "\n",
    "    x, y = depth_df_x[f'x{t}']/1000, depth_df_y[f'y{t}']/1000\n",
    "\n",
    "    ax.plot(x, y, depth_df_x.index)\n",
    "ax.view_init(elev=10, azim=135)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
