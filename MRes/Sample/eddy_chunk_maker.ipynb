{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95c040d-0297-43dd-b550-76c70f69ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ROMS_26yr_daydic.pkl', 'rb') as file:\n",
    "    daydic = pickle.load(file)\n",
    "\n",
    "with open('ROMS_26yr_eddies.pkl', 'rb') as file:\n",
    "    eddies = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b4f75e-7fd3-46c9-88ec-f2b3f28f9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "\n",
    "fname = '/srv/scratch/z3533156/26year_BRAN2020/outer_avg_01461.nc'\n",
    "dataset = nc.Dataset(fname)\n",
    "lon_rho  = dataset.variables['lon_rho'][:]\n",
    "lon_rho = np.transpose(lon_rho, axes=(1, 0))\n",
    "lat_rho  = dataset.variables['lat_rho'][:]\n",
    "lat_rho = np.transpose(lat_rho, axes=(1, 0))\n",
    "f  = dataset.variables['f'][:]\n",
    "f = np.transpose(f, axes=(1, 0))\n",
    "h = dataset.variables['h'][:]\n",
    "h = np.transpose(h, axes=(1, 0))\n",
    "z_r = np.load('/home/z5297792/UNSW-MRes/MRes/z_r/z_r.npy')\n",
    "z_r = np.transpose(z_r, (1, 2, 0))\n",
    "temp_ave = np.load('/srv/scratch/z5297792/Climatology/temp_ave.npy')\n",
    "CurSpeed_ave = np.load('/srv/scratch/z5297792/Climatology/CurSpeed_ave.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f57fe3-a34b-4aef-95e5-f9b85c52da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_number(s):\n",
    "    match = re.search(r'\\d+', s)\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "def eddies_nearest_rho(elon, elat):\n",
    "    dataset = nc.Dataset('/srv/scratch/z3533156/26year_BRAN2020/outer_avg_01461.nc')\n",
    "    lon_rho = np.transpose(dataset.variables['lon_rho'], axes=(1, 0))\n",
    "    lat_rho = np.transpose(dataset.variables['lat_rho'], axes=(1, 0))\n",
    "    R = np.sqrt((lon_rho - elon)**2 + (lat_rho - elat)**2)\n",
    "    i_search, j_search = np.unravel_index(np.argmin(R), R.shape)\n",
    "    return i_search, j_search\n",
    "\n",
    "def grid_finder(i_search, j_search, SEARCH_WIDTH):\n",
    "    fname = '/srv/scratch/z3533156/26year_BRAN2020/outer_avg_01461.nc'\n",
    "    dataset = nc.Dataset(fname)\n",
    "    lon_rho = np.transpose(dataset.variables['lon_rho'], axes=(1, 0))\n",
    "    lat_rho = np.transpose(dataset.variables['lat_rho'], axes=(1, 0))\n",
    "    \n",
    "    def within_search_width(i_offset, j_offset):\n",
    "        return distance(lat_rho[i_search, j_search], lon_rho[i_search, j_search],\n",
    "                        lat_rho[i_search + i_offset, j_search + j_offset], \n",
    "                        lon_rho[i_search + i_offset, j_search + j_offset]) < SEARCH_WIDTH / 2\n",
    "\n",
    "    i_left, i_right = 0, 0\n",
    "    j_down, j_up = 0, 0\n",
    "\n",
    "    while i_search - i_left >= 0 and within_search_width(-i_left, 0):\n",
    "        i_left += 1\n",
    "    while i_search + i_right < lon_rho.shape[0] and within_search_width(i_right, 0):\n",
    "        i_right += 1\n",
    "    while j_search - j_down >= 0 and within_search_width(0, -j_down):\n",
    "        j_down += 1\n",
    "    while j_search + j_up < lon_rho.shape[1] and within_search_width(0, j_up):\n",
    "        j_up += 1\n",
    "\n",
    "    i_left = max(i_search - i_left + 1, 0)\n",
    "    i_right = min(i_search + i_right, lon_rho.shape[0])\n",
    "    j_down = max(j_search - j_down + 1, 0)\n",
    "    j_up = min(j_search + j_up, lon_rho.shape[1])\n",
    "\n",
    "    return i_left, i_right, j_down, j_up\n",
    "\n",
    "def eddy_centric_grid_distances(i_search, j_search, i_left, i_right, j_down, j_up):\n",
    "    lonc = lon_rho[i_search, j_search]\n",
    "    latc = lat_rho[i_search, j_search]\n",
    "    def make_left_values_negative(arr):\n",
    "        zero_index = np.where(arr == 0)[0]\n",
    "        if zero_index.size == 0:\n",
    "            return arr\n",
    "        zero_index = zero_index[0]\n",
    "        arr[:zero_index] = -np.abs(arr[:zero_index])\n",
    "        return arr\n",
    "    x = make_left_values_negative(distance(latc, lonc, lat_rho[i_left:i_right,j_search], lon_rho[i_left:i_right,j_search]))\n",
    "    y = make_left_values_negative(distance(latc, lonc, lat_rho[i_search,j_down:j_up], lon_rho[i_search,j_down:j_up]))\n",
    "    return x.data, y.data\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    EARTH_RADIUS = 6357000\n",
    "    lat1_rad, lon1_rad = np.radians(lat1), np.radians(lon1)\n",
    "    lat2_rad, lon2_rad = np.radians(lat2), np.radians(lon2)\n",
    "    dlat, dlon = lat2_rad - lat1_rad, lon2_rad - lon1_rad\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    return EARTH_RADIUS * 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b08348-92bf-4890-a5b1-914f033bab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_velocity(eddy_name, eddies):\n",
    "    edata = eddies[eddy_name]\n",
    "    \n",
    "    # Extract middle 30 days\n",
    "    middle_index = edata.shape[0] // 2\n",
    "    t0 = extract_number(edata.iloc[middle_index - 15].name) \n",
    "    tN = extract_number(edata.iloc[middle_index + 15].name) \n",
    "    \n",
    "    # Initialize arrays\n",
    "    U1 = np.zeros((lon_rho.shape[0], lon_rho.shape[1], z_r.shape[-1], tN - t0))\n",
    "    V1 = np.zeros_like(U1)\n",
    "    \n",
    "    # Calculate time moduli and file indices\n",
    "    t_mod0, t_modN = t0 % 30, tN % 30\n",
    "    file_idx0, file_idxN = int(t0 // 30), int(tN // 30)\n",
    "    t_pres = 30 - t_mod0\n",
    "    \n",
    "    for file_idx in range(file_idx0, file_idxN + 1):\n",
    "        fnumber = str(f\"{1461 + file_idx * 30:05d}\")\n",
    "        \n",
    "        # Calculate start and end indices\n",
    "        start_idx = t_mod0 if file_idx == file_idx0 else 0\n",
    "        end_idx = t_modN if file_idx == file_idxN else 30\n",
    "        \n",
    "        # Load data from the file\n",
    "        U_chunk = np.load(f'/srv/scratch/z5297792/Climatology/u_v/u_{fnumber}.npy')[:, :, :, start_idx:end_idx]\n",
    "        V_chunk = np.load(f'/srv/scratch/z5297792/Climatology/u_v/v_{fnumber}.npy')[:, :, :, start_idx:end_idx]\n",
    "        \n",
    "        # Fill data into arrays\n",
    "        if file_idx == file_idx0:\n",
    "            U1[:, :, :, :t_pres] = U_chunk\n",
    "            V1[:, :, :, :t_pres] = V_chunk\n",
    "        elif file_idx == file_idxN:\n",
    "            U1[:, :, :, t_pres:] = U_chunk\n",
    "            V1[:, :, :, t_pres:] = V_chunk\n",
    "        else:\n",
    "            U1[:, :, :, t_pres:(t_pres + 30)] = U_chunk\n",
    "            V1[:, :, :, t_pres:(t_pres + 30)] = V_chunk\n",
    "            t_pres += 30\n",
    "    \n",
    "    # Set invalid data to NaN\n",
    "    U1 = np.where(np.abs(U1) > 1e30, np.nan, U1)\n",
    "    V1 = np.where(np.abs(V1) > 1e30, np.nan, V1)\n",
    "    \n",
    "    return U1, V1\n",
    "\n",
    "def interpolate_to_dx_spacing(x, y, Z, dx):\n",
    "    # Define x and y ranges based on dx\n",
    "    x_min, x_max = np.round(np.array([np.min(x), np.max(x)]) / dx) * dx\n",
    "    y_min, y_max = np.round(np.array([np.min(y), np.max(y)]) / dx) * dx\n",
    "\n",
    "    xy_abs = min(abs(x_min), abs(x_max), abs(y_min), abs(y_max))\n",
    "    x_new = np.arange(-xy_abs, xy_abs + dx, dx)\n",
    "    y_new = np.arange(-xy_abs, xy_abs + dx, dx)\n",
    "    \n",
    "    # Create the new interpolated Z array with shape (len(y_new), len(x_new), depth_levels)\n",
    "    depth_levels = Z.shape[2]\n",
    "    Z_new = np.zeros((len(y_new), len(x_new), depth_levels))\n",
    "    \n",
    "    # Interpolate at each depth level\n",
    "    for k in range(depth_levels):\n",
    "        original_points = np.array(np.meshgrid(x, y)).T.reshape(-1, 2)\n",
    "        values = Z[:, :, k].flatten()\n",
    "        new_points = np.array(np.meshgrid(x_new, y_new)).T.reshape(-1, 2)\n",
    "        \n",
    "        Z_new[:, :, k] = griddata(original_points, values, new_points, method='linear').reshape(len(y_new), len(x_new))\n",
    "    \n",
    "    return x_new, y_new, Z_new\n",
    "\n",
    "def chunk_interpolator(t, U1, V1, depth_lvl_limit):\n",
    "\n",
    "    t0 = eddies[sample_eddy].shape[0] // 2 - 15\n",
    "    t_eddy_relative = t + t0\n",
    "    edata = eddies[sample_eddy].iloc[t_eddy_relative]\n",
    "    i_search, j_search = eddies_nearest_rho(edata.Lon, edata.Lat)\n",
    "    \n",
    "    i_left, i_right, j_down, j_up = grid_finder(i_search, j_search, SEARCH_WIDTH)\n",
    "    x_roms, y_roms = eddy_centric_grid_distances(i_search, j_search, i_left, i_right, j_down, j_up)\n",
    "\n",
    "    _, _, U = interpolate_to_dx_spacing(x_roms, y_roms, U1[i_left:i_right, j_down:j_up,:depth_lvl_limit,t], dx)\n",
    "    x, y, V = interpolate_to_dx_spacing(x_roms, y_roms, V1[i_left:i_right, j_down:j_up,:depth_lvl_limit,t], dx)\n",
    "\n",
    "    return {'U': U, 'V': V, 'x': x, 'y': y, 'z': z_r[150, 150, :depth_lvl_limit]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e41ec5-403d-4252-8f08-dc2ab059eec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 188.1065 seconds\n",
      "Eddy790\n",
      "Elapsed time: 157.0072 seconds\n",
      "Eddy110\n",
      "Elapsed time: 170.4937 seconds\n",
      "Eddy134\n",
      "Elapsed time: 152.6023 seconds\n",
      "Eddy775\n"
     ]
    }
   ],
   "source": [
    "SEARCH_WIDTH = 300000\n",
    "dx = 3000\n",
    "\n",
    "# sample_eddies = daydic['Day500'].loc[daydic['Day500']['Age'] > 60].index\n",
    "\n",
    "the_frontier_eddies = ['Eddy790', 'Eddy110', 'Eddy134', 'Eddy775']\n",
    "\n",
    "sample_data = {}\n",
    "for sample_eddy in the_frontier_eddies:\n",
    "    tic = time.time()\n",
    "    U1, V1 = extract_velocity(sample_eddy, eddies)\n",
    "\n",
    "    depth_lvl_limit = 30\n",
    "\n",
    "    sample_data[sample_eddy] = {f'T{t}': chunk_interpolator(t, U1, V1, depth_lvl_limit) for t in range(U1.shape[-1])}\n",
    "    toc = time.time()\n",
    "    print(f\"Elapsed time: {toc - tic:.4f} seconds\")\n",
    "    print(sample_eddy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5b72ab-6556-4099-93c0-978ec69ef150",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/srv/scratch/z5297792/Sample/frontier_sample_data.pkl', 'wb') as file:\n",
    "    pickle.dump(sample_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184400d-3333-45fc-819f-705963ff095d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9fc68-aaeb-4f9f-9927-10365603bd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeebb95-0e19-498c-849a-7c0cbca8edd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
