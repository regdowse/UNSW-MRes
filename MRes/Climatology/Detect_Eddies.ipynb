{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Eddy Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import isnan\n",
    "import pickle\n",
    "\n",
    "\n",
    "def detect_eddy_centers(u_surf_t, v_surf_t, ssh_t, ow_surf_t, cur_speed_surf_t):\n",
    "\n",
    "    def find_local_maxima(matrix):\n",
    "        local_maxima = []\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix[0])):\n",
    "                if is_local_max(matrix, i, j):\n",
    "                    local_maxima.append((i, j))\n",
    "        return local_maxima\n",
    "\n",
    "    def is_local_max(matrix, row, col):\n",
    "        current_value = matrix[row][col]\n",
    "        if row > 0 and current_value <= matrix[row - 1][col]:\n",
    "            return False\n",
    "        if row < len(matrix) - 1 and current_value <= matrix[row + 1][col]:\n",
    "            return False\n",
    "        if col > 0 and current_value <= matrix[row][col - 1]:\n",
    "            return False\n",
    "        if col < len(matrix[0]) - 1 and current_value <= matrix[row][col + 1]:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    ssh_t[ssh_t > 5] = 0\n",
    "    local_ssh_max = set(find_local_maxima(ssh_t))\n",
    "    local_ssh_min = set(find_local_maxima(-ssh_t))\n",
    "    ssh_peaks_coord = local_ssh_max.union(local_ssh_min)\n",
    "    # CRITICAL CURRENT SPEED\n",
    "    mask = cur_speed_surf_t < 1\n",
    "    crit_cur_speed_r, crit_cur_speed_c = np.where(mask)\n",
    "    crit_cur_coord = set(list(zip(crit_cur_speed_r, crit_cur_speed_c)))\n",
    "    # LARGE NEGATIVE OW\n",
    "    mask = ow_surf_t < 0\n",
    "    lrg_ow_surf_r, lrg_ow_surf_c = np.where(mask)\n",
    "    lrg_ow_surf_coord = set(list(zip(lrg_ow_surf_r, lrg_ow_surf_c)))\n",
    "    # POTENTIAL CENTERS\n",
    "    pot = lrg_ow_surf_coord & crit_cur_coord\n",
    "    pot = pot & ssh_peaks_coord\n",
    "    if len(pot) != 0:\n",
    "        pot_list = list(pot)\n",
    "        pot_r, pot_c = zip(*pot_list)\n",
    "        X = np.column_stack((list(lon_rho[pot_r,pot_c]),list(lat_rho[pot_r,pot_c])))\n",
    "        # Set the distance threshold\n",
    "        DIST_BTW_EDDIES = 0.33\n",
    "        # Perform DBSCAN clustering\n",
    "        dbscan = DBSCAN(eps=DIST_BTW_EDDIES, min_samples=1)\n",
    "        eddy_id = dbscan.fit_predict(X)\n",
    "        C = []\n",
    "        for eddy in range(1, np.max(eddy_id) + 1):\n",
    "            mean_lon = np.mean(X[eddy_id == eddy, 0])\n",
    "            mean_lat = np.mean(X[eddy_id == eddy, 1])\n",
    "            C.append((mean_lon, mean_lat))\n",
    "    else:\n",
    "        C = [(np.nan, np.nan)]\n",
    "    return C\n",
    "\n",
    "def day_dic_making(u_surf, v_surf, ssh, vort_surf, ow_surf, cur_speed_surf, lon_rho, lat_rho):\n",
    "    daydic = {}\n",
    "\n",
    "    for TIME in range(30):\n",
    "        u_surf_t = u_surf[:, :, TIME].squeeze()\n",
    "        v_surf_t = v_surf[:, :, TIME].squeeze()\n",
    "        ssh_t = ssh[:, :, TIME].squeeze()\n",
    "        ow_surf_t = ow_surf[:, :, TIME].squeeze()\n",
    "        cur_speed_surf_t = cur_speed_surf[:, :, TIME].squeeze()\n",
    "        vort_surf_t = vort_surf[:, :, TIME].squeeze()\n",
    "        centers = detect_eddy_centers(u_surf_t, v_surf_t, ssh_t, ow_surf_t, cur_speed_surf_t)\n",
    "\n",
    "        Clon = list(zip(*centers))[0]\n",
    "        Clat = list(zip(*centers))[1]\n",
    "\n",
    "        eVort = []\n",
    "        for e in range(len(Clon)):\n",
    "            R2 = (lon_rho - centers[e][0])**2 + (lat_rho - centers[e][1])**2\n",
    "            ic, jc = np.unravel_index(np.argmin(R2, axis=None), R2.shape)\n",
    "            eVort.append(vort_surf_t[ic, jc])\n",
    "\n",
    "        id = np.arange(1, len(Clon) + 1)\n",
    "\n",
    "        dsum = {\n",
    "            'Clon': Clon,\n",
    "            'Clat': Clat,\n",
    "            'Vort': eVort,\n",
    "            'id': id\n",
    "        }\n",
    "\n",
    "        index_labels = [f'Eddy{n}' for n in range(1, len(Clon) + 1)]\n",
    "        ddata = pd.DataFrame(dsum, index=index_labels)\n",
    "        daydic[f'Day{TIME + 1}'] = ddata\n",
    "\n",
    "    return daydic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnumbers = [f'{num:05}' for num in range(1461, 10611+1, 30)] # last valid file is 10611 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01461\n",
      "02061\n",
      "02661\n",
      "03261\n",
      "03861\n",
      "04461\n",
      "05061\n",
      "05661\n",
      "06261\n",
      "06861\n",
      "07461\n",
      "08061\n",
      "08661\n",
      "09261\n",
      "09861\n",
      "10461\n"
     ]
    }
   ],
   "source": [
    "ROMS_directory = {}\n",
    "\n",
    "fname = '/srv/scratch/z3533156/26year_BRAN2020/outer_avg_'+str(fnumbers[0])+'.nc'\n",
    "\n",
    "dataset = nc.Dataset(fname)\n",
    "angle = dataset.variables['angle']\n",
    "angle = angle[0,0]\n",
    "lon_rho  = dataset.variables['lon_rho']\n",
    "lon_rho = np.transpose(lon_rho, axes=(1, 0))\n",
    "lat_rho  = dataset.variables['lat_rho']\n",
    "lat_rho = np.transpose(lat_rho, axes=(1, 0))\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    EARTH_RADIUS = 6357000  # in meters\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "    # Haversine formula\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return EARTH_RADIUS * c\n",
    "dx = distance(lat_rho[:-1, :], lon_rho[:-1, :], lat_rho[1:, :], lon_rho[1:, :])\n",
    "dy = distance(lat_rho[:, :-1], lon_rho[:, :-1], lat_rho[:, 1:], lon_rho[:, 1:])\n",
    "dx = np.repeat(dx[:, :, np.newaxis], 30, axis=2)\n",
    "dy = np.repeat(dy[:, :, np.newaxis], 30, axis=2)\n",
    "\n",
    "i_print = 0\n",
    "for fnumber in fnumbers:\n",
    "\n",
    "    if i_print % 20 == 0:\n",
    "        print(fnumber)\n",
    "    i_print += 1\n",
    "   \n",
    "    fname = '/srv/scratch/z3533156/26year_BRAN2020/outer_avg_'+str(fnumber)+'.nc'\n",
    "    dataset = nc.Dataset(fname)\n",
    "    u_east = dataset.variables['u_eastward']\n",
    "    u_east = np.transpose(u_east, axes=(3, 2, 1, 0))\n",
    "    u_east_surf = u_east[:,:,-1,:].squeeze()\n",
    "    del u_east \n",
    "    v_north = dataset.variables['v_northward']\n",
    "    v_north = np.transpose(v_north, axes=(3, 2, 1, 0))\n",
    "    v_north_surf = v_north[:,:,-1,:].squeeze()\n",
    "    del v_north\n",
    "    ssh = dataset.variables['zeta']\n",
    "    ssh = np.transpose(ssh, axes=(2, 1, 0))\n",
    "    size_u_east_surf = u_east_surf.shape\n",
    "    size_v_north_surf = v_north_surf.shape\n",
    "    u_surf = np.full(size_u_east_surf, np.nan)\n",
    "    v_surf = np.full(size_v_north_surf, np.nan)\n",
    "    for TIME in range(30):\n",
    "        u_surf[:,:,TIME] = v_north_surf[:,:,TIME] * np.sin(angle) + u_east_surf[:,:,TIME] * np.cos(angle)\n",
    "        v_surf[:,:,TIME] = v_north_surf[:,:,TIME] * np.cos(angle) - u_east_surf[:,:,TIME] * np.sin(angle)\n",
    "    del u_east_surf, v_north_surf\n",
    "    # CHANGES IN VELOCITIES\n",
    "    # For u_x\n",
    "    u_x = (u_surf[2:,:,:] - u_surf[:-2,:,:]) / (dx[:-1,:] + dx[1:,:])\n",
    "    # For u_y\n",
    "    u_y = (u_surf[:,2:,:] - u_surf[:,:-2,:]) / (dy[:,:-1] + dy[:,1:])\n",
    "    # For v_x\n",
    "    v_x = (v_surf[2:,:,:] - v_surf[:-2,:,:]) / (dx[:-1,:] + dx[1:,:])\n",
    "    # For v_y\n",
    "    v_y = (v_surf[:,2:,:] - v_surf[:,:-2,:]) / (dy[:,:-1] + dy[:,1:])\n",
    "    WIDTH, LENGTH = lat_rho.shape\n",
    "    TOTAL_NUM_DAYS = 30\n",
    "    # For u_x\n",
    "    u_x = np.concatenate((np.zeros((1, LENGTH, TOTAL_NUM_DAYS)), u_x, np.zeros((1, LENGTH, TOTAL_NUM_DAYS))), axis=0)\n",
    "    # For v_x\n",
    "    v_x = np.concatenate((np.zeros((1, LENGTH, TOTAL_NUM_DAYS)), v_x, np.zeros((1, LENGTH, TOTAL_NUM_DAYS))), axis=0)\n",
    "    # For u_y\n",
    "    u_y = np.concatenate((np.zeros((WIDTH, 1, TOTAL_NUM_DAYS)), u_y, np.zeros((WIDTH, 1, TOTAL_NUM_DAYS))), axis=1)\n",
    "    # For v_y\n",
    "    v_y = np.concatenate((np.zeros((WIDTH, 1, TOTAL_NUM_DAYS)), v_y, np.zeros((WIDTH, 1, TOTAL_NUM_DAYS))), axis=1)\n",
    "    # NORMAL STRAIN\n",
    "    s_n_surf = u_x - v_y\n",
    "    # SHEAR STRAIN\n",
    "    s_s_surf = v_x + u_y\n",
    "    # VORTICITY\n",
    "    vort_surf = v_x - u_y\n",
    "    # OKUBO-WEISS\n",
    "    ow_surf = s_n_surf**2 + s_s_surf**2 - vort_surf**2\n",
    "    # Set boundary values to large positive\n",
    "    ow_surf[0, :] = 10        # Top row\n",
    "    ow_surf[-1, :] = 10       # Bottom row\n",
    "    ow_surf[:, 0] = 10        # Left column\n",
    "    ow_surf[:, -1] = 10       # Right column\n",
    "    # CURRENT SPEED\n",
    "    cur_speed_surf = np.sqrt(u_surf**2 + v_surf**2)\n",
    "\n",
    "    del u_x, v_x, u_y, v_y, s_n_surf, s_s_surf\n",
    "\n",
    "    ROMS_directory[fnumber] = day_dic_making(u_surf, v_surf, ssh, vort_surf, ow_surf, cur_speed_surf, lon_rho, lat_rho)\n",
    "\n",
    "del dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel days 30, 31, 32, ...\n",
    "n = 0\n",
    "for data_file in ROMS_directory.keys():\n",
    "    ROMS_directory[data_file] = {f'Day{i + 30*n}': v for k, v in ROMS_directory[data_file].items() for i in [int(k[3:])]}\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all days\n",
    "ROMS_daydic = {}\n",
    "for d in ROMS_directory.values():\n",
    "    ROMS_daydic.update(d)\n",
    "\n",
    "del ROMS_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eddy_tracking(daydic):\n",
    "\n",
    "    next_num = max(list(range(1,daydic['Day1'].shape[0])))+1\n",
    "    for day in range(2, len(daydic)+1):\n",
    "        ddata_pre = daydic['Day'+str(day-1)]\n",
    "        ddata_post = daydic['Day'+str(day)]\n",
    "        pre_C_lon  = ddata_pre.Clon\n",
    "        pre_C_lat  = ddata_pre.Clat\n",
    "        post_C_lon  = ddata_post.Clon\n",
    "        post_C_lat  = ddata_post.Clat\n",
    "        pre_vort  = ddata_pre.Vort\n",
    "        post_vort  = ddata_post.Vort\n",
    "        id = np.full(len(post_C_lon), np.nan)\n",
    "        VORT_WEIGHT = .5*1E9\n",
    "        for j in range(len(post_C_lon)):\n",
    "            for i in range(len(pre_C_lon)):\n",
    "                R = np.sqrt((pre_C_lon[i] - post_C_lon[j])**2 + (pre_C_lat[i] - post_C_lat[j])**2 + VORT_WEIGHT*(pre_vort[i]-post_vort[j])**2)\n",
    "                if R < .5 and not any(id == ddata_pre.id[i]):\n",
    "                    id[j] = int(ddata_pre.id[i])\n",
    "            for BACK_CHECK in range(2, 5):\n",
    "                if np.isnan(id[j]) and day > BACK_CHECK:\n",
    "                    pre_C_lon = daydic['Day'+str(day-BACK_CHECK)].Clon\n",
    "                    pre_C_lat = daydic['Day'+str(day-BACK_CHECK)].Clat\n",
    "                    pre_vort = daydic['Day'+str(day-BACK_CHECK)].Vort\n",
    "                    for i in range(len(pre_C_lat)):\n",
    "                        R = np.sqrt((pre_C_lon[i] - post_C_lon[j])**2 + (pre_C_lat[i] - post_C_lat[j])**2 + VORT_WEIGHT*(pre_vort[i]-post_vort[j])**2)\n",
    "                        if R < .5 and not any(id == daydic['Day'+str(day-BACK_CHECK)].id[i]):\n",
    "                            id[j] = int(daydic['Day'+str(day-BACK_CHECK)].id[i])\n",
    "            ddata_pre = daydic['Day'+str(day-1)]\n",
    "            pre_C_lon  = ddata_pre.Clon\n",
    "            pre_C_lat  = ddata_pre.Clat\n",
    "            pre_vort = ddata_pre.Vort\n",
    "            if np.isnan(id[j]):\n",
    "                id[j] = next_num\n",
    "                next_num += 1\n",
    "        id = [round(x) for x in id]\n",
    "        ddata_post = daydic['Day'+str(day)]\n",
    "        ddata_post.id = id\n",
    "        ddata_post.index = ['Eddy' + str(i) for i in id]\n",
    "    \n",
    "    return daydic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/pbs.5591090.kman.restech.unsw.edu.au/ipykernel_4080539/3522796099.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R = np.sqrt((pre_C_lon[i] - post_C_lon[j])**2 + (pre_C_lat[i] - post_C_lat[j])**2 + VORT_WEIGHT*(pre_vort[i]-post_vort[j])**2)\n",
      "/scratch/pbs.5591090.kman.restech.unsw.edu.au/ipykernel_4080539/3522796099.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if R < .5 and not any(id == ddata_pre.id[i]):\n",
      "/scratch/pbs.5591090.kman.restech.unsw.edu.au/ipykernel_4080539/3522796099.py:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  id[j] = int(ddata_pre.id[i])\n",
      "/scratch/pbs.5591090.kman.restech.unsw.edu.au/ipykernel_4080539/3522796099.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  R = np.sqrt((pre_C_lon[i] - post_C_lon[j])**2 + (pre_C_lat[i] - post_C_lat[j])**2 + VORT_WEIGHT*(pre_vort[i]-post_vort[j])**2)\n",
      "/scratch/pbs.5591090.kman.restech.unsw.edu.au/ipykernel_4080539/3522796099.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if R < .5 and not any(id == daydic['Day'+str(day-BACK_CHECK)].id[i]):\n",
      "/scratch/pbs.5591090.kman.restech.unsw.edu.au/ipykernel_4080539/3522796099.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  id[j] = int(daydic['Day'+str(day-BACK_CHECK)].id[i])\n"
     ]
    }
   ],
   "source": [
    "ROMS_daydic_tracked = eddy_tracking(ROMS_daydic)\n",
    "del ROMS_daydic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eddy_dic_making(daydic,meso_age):\n",
    "\n",
    "    def distance_between_non_nan(lst):\n",
    "        first_non_nan = None\n",
    "        last_non_nan = None\n",
    "        for i in range(len(lst)):\n",
    "            if not isinstance(lst[i], float) or not math.isnan(lst[i]):\n",
    "                first_non_nan = i\n",
    "                break\n",
    "        for i in range(len(lst) - 1, -1, -1):\n",
    "            if not isinstance(lst[i], float) or not math.isnan(lst[i]):\n",
    "                last_non_nan = i\n",
    "                break\n",
    "        if first_non_nan is not None and last_non_nan is not None:\n",
    "            distance = last_non_nan - first_non_nan + 1\n",
    "            return distance\n",
    "        else:\n",
    "            return None  \n",
    "\n",
    "    max_id = max([max(daydic[key].id) for key in daydic.keys()])\n",
    "\n",
    "    eddies = {}\n",
    "\n",
    "    for e in range(1, max_id + 1):\n",
    "        eLon = []\n",
    "        eLat = []\n",
    "        eVort = []\n",
    "        eId = []\n",
    "\n",
    "        id = 0\n",
    "        for dayinfo in daydic.values():\n",
    "            if f'Eddy{e}' in dayinfo.index:\n",
    "                dayeddyinfo = dayinfo.loc[f'Eddy{e}']\n",
    "                eLon.append(dayeddyinfo.Clon)\n",
    "                eLat.append(dayeddyinfo.Clat)\n",
    "                eVort.append(dayeddyinfo.Vort)\n",
    "                eId.append(round(dayeddyinfo.id))\n",
    "                id = dayeddyinfo.id\n",
    "            else:\n",
    "                eLon.append(np.nan)\n",
    "                eLat.append(np.nan)\n",
    "                eVort.append(np.nan)\n",
    "                eId.append(np.nan)\n",
    "\n",
    "        eAge = [distance_between_non_nan(eLon)] * len(daydic)\n",
    "        # give id even for ghost centers\n",
    "        eId = [id] * len(daydic)\n",
    "\n",
    "        ed = pd.DataFrame({\n",
    "            'Lon': eLon,\n",
    "            'Lat': eLat,\n",
    "            'Vort': eVort,\n",
    "            'Id': eId,\n",
    "            'Age': eAge\n",
    "        }, index=[d for d in daydic.keys()])\n",
    "\n",
    "        # Interpolate values for Lon, Lat, Vort\n",
    "        first_non_nan = ed['Lon'].first_valid_index()\n",
    "        last_non_nan = ed['Lon'].last_valid_index()\n",
    "        \n",
    "        ed.loc[first_non_nan:last_non_nan, 'Lon'] = ed.loc[first_non_nan:last_non_nan, 'Lon'].interpolate()\n",
    "        ed.loc[first_non_nan:last_non_nan, 'Lat'] = ed.loc[first_non_nan:last_non_nan, 'Lat'].interpolate()\n",
    "        ed.loc[first_non_nan:last_non_nan, 'Vort'] = ed.loc[first_non_nan:last_non_nan, 'Vort'].interpolate()\n",
    "\n",
    "        def same_sign(vector):\n",
    "\n",
    "            vector = [x for x in vector if not math.isnan(x)]\n",
    "            non_zero_values = [x for x in vector if x != 0]\n",
    "            if not non_zero_values:  \n",
    "                return True\n",
    "            first_sign = non_zero_values[0] > 0\n",
    "            for value in non_zero_values:\n",
    "                if (value > 0) != first_sign:\n",
    "                    return False\n",
    "            return True\n",
    "            \n",
    "        if eAge[0] is not None:\n",
    "            if eAge[0] >= meso_age and same_sign(eVort):\n",
    "\n",
    "                ed = ed[~ed['Lon'].isna()]\n",
    "                \n",
    "                eddies[f'Eddy{e}'] = ed\n",
    "    \n",
    "    eddies = {f'Eddy{i+1}': value for i, (key, value) in enumerate(eddies.items())}\n",
    "\n",
    "    i = 1\n",
    "    for e in eddies.keys():\n",
    "        eddies[e].Id = np.ones(eddies[e].Id.shape) * i\n",
    "        i += 1\n",
    "\n",
    "    # Remove excess data\n",
    "    for eddy in eddies.keys():\n",
    "        eddies[eddy] = eddies[eddy][~eddies[eddy]['Lon'].isna()]\n",
    "\n",
    "    return eddies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather mesoscale eddies\n",
    "meso_age = 10\n",
    "ROMS_eddies = eddy_dic_making(ROMS_daydic_tracked, meso_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_daydic(daydic, eddies):\n",
    "    clean_daydic = {}\n",
    "\n",
    "    for d in daydic.keys():\n",
    "\n",
    "        lon = []\n",
    "        lat = []\n",
    "        vort = []\n",
    "        idd = []\n",
    "        age = []\n",
    "\n",
    "        for e in eddies.keys():\n",
    "\n",
    "\n",
    "            if d in eddies[e].index:\n",
    "\n",
    "                lon.append(eddies[e].loc[d].Lon)\n",
    "                lat.append(eddies[e].loc[d].Lat)\n",
    "                vort.append(eddies[e].loc[d].Vort)\n",
    "                idd.append(round(eddies[e].loc[d].Id))\n",
    "                age.append(round(eddies[e].loc[d].Age))\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "                'Lon': lon,\n",
    "                'Lat': lat,\n",
    "                'Vort': vort,\n",
    "                'Id': idd,\n",
    "                'Age': age\n",
    "            }, index=[f'Eddy{i}' for i in idd])\n",
    "\n",
    "        clean_daydic[d] = df\n",
    "\n",
    "    return clean_daydic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROMS_daydic_meso = clean_daydic(ROMS_daydic_tracked, ROMS_eddies)\n",
    "del ROMS_daydic_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ROMS_26yr_daydic.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(ROMS_daydic_meso, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ROMS_26yr_eddies.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(ROMS_eddies, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "print('Complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
