{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5edc55fb",
   "metadata": {},
   "source": [
    "## Classifying fishsop data into up and downcast ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bba3d3-b6c7-4f6a-a6b1-8c347145940d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6453ed52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fishsoop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfishsoop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#from fishsoop.example_scripts import cast_time_QC\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fishsoop'"
     ]
    }
   ],
   "source": [
    "# Import libs #\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fishsoop.io import load_data\n",
    "#from fishsoop.example_scripts import cast_time_QC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e488984",
   "metadata": {},
   "source": [
    "### Select data based on region of interest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a82749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:/Users/z5493451/OneDrive - UNSW/Documents/Data/FishSOOP/IMOS_SOOP-FishSOOP_TP_FV01.parquet'\n",
    "path = \"/g/data/yj27/data/obs/fishsoop/IMOS_SOOP-FishSOOP_TP_FV01.parquet\"\n",
    "df = load_data(\n",
    "    path_to_file=path,\n",
    "    date_start=\"01-08-2023\",\n",
    "    date_end=\"01-08-2024\",\n",
    "    longitude_min=147.1,\n",
    "    longitude_max=162.218,\n",
    "    latitude_min=-41.545,\n",
    "    latitude_max=-25.117,\n",
    "    depth_min=None,\n",
    "    depth_max=None,\n",
    "    sensor_serial=None,\n",
    "    gear_type=None\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6b0a3",
   "metadata": {},
   "source": [
    "### Load the moana sensor data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select the first cast\n",
    "first_cast = df.index.get_level_values(0)[0]\n",
    "df_first = df.xs(first_cast, level=0)\n",
    "#df_first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f454af",
   "metadata": {},
   "source": [
    "### Separate time series into upcast, downcast, and staitonary (everything in between) ###\n",
    "\n",
    "Now that we have a large sample of moana sensor cast data, we will test an algorithm to sort each cast into different cast components.\n",
    "Once the algorithm is working, we will be able to add into the accessors in the fishsoop package to do this automatically for any cast on the fly.\n",
    "\n",
    "The function we will use is in the 'example_scripts' file in the fishsoop library and is called 'classify_casts'. It requires a series of timedeltas (generally in seconds) and array of depths to work. It is designed to do any sorting automatically without user intervention (which is why it must be tested vigarously!) by adopting a 'flipper' strategy (flips the series to pinpoint the end of the upcast), a clustering process to determine if depth is increasing, decreasing, or remaining constant, and a spline smoothing process to account for noise. For more information, see the function documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE USSAGE FOR 1 DATAFRAME --------------------------------------------------------------- #\n",
    "time = (df_first.TIME.values - df_first.TIME.values[0]).astype('timedelta64[s]').view('int64')\n",
    "depth = df_first.index.values\n",
    "temp = df_first.TEMPERATURE.values\n",
    "\n",
    "labels = cast_time_QC(time, depth, ref_depth=4, time_limit=15)\n",
    "\n",
    "# EXAMPLE PLOT ----------------------------------------------------------------- #\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Color mapping\n",
    "colors = {1: 'dodgerblue', 2: 'crimson', 3: 'gainsboro'}\n",
    "label_colors = [colors[label] for label in labels]\n",
    "\n",
    "# Plot 1: Depth vs Time\n",
    "ax1.scatter(time, depth, c=label_colors, alpha=0.6, s=10)\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Depth (m)')\n",
    "ax1.set_title('Depth vs Time (Classified)')\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "for label, color in colors.items():\n",
    "    ax1.scatter([], [], c=color, label=label, s=50)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Temperature vs Depth\n",
    "ax2.scatter(temp, depth, c=label_colors, alpha=0.6, s=10)\n",
    "ax2.set_xlabel('Temperature (°C)')\n",
    "ax2.set_ylabel('Depth (m)')\n",
    "ax2.set_title('Temperature vs Depth (Classified)')\n",
    "ax2.invert_yaxis()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Classification segments\n",
    "unique_labels = np.unique(labels)\n",
    "y_positions = {1: 1, 3: 0, 2: -1}\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    ax3.scatter(time[i], y_positions[label], c=colors[label], alpha=0.6, s=20)\n",
    "\n",
    "ax3.set_xlabel('Time (s)')\n",
    "ax3.set_ylabel('Cast Type')\n",
    "ax3.set_yticks([-1, 0, 1])\n",
    "ax3.set_yticklabels(['Upcast', 'Stationary', 'Downcast'])\n",
    "ax3.set_title('Classification Timeline')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9945e",
   "metadata": {},
   "source": [
    "When the classify cast function is used, it returns a list of labels which correspond to the state of the sensor (i.e., 'downcast', 'upcast', or 'stationary') which can be assigned to the dataset. This is how the function can eventually be implemented as an xarray accessor - by asigning the values directly to the dataset when ds.upcast/downcast is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30255f",
   "metadata": {},
   "source": [
    "Now, we will go through some of the datasets iteratively to test the function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FUNCTION FOR TESTS --------------------------------------------------------------- #\n",
    "def castplot(time, depth, labels):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3), dpi=200)\n",
    "\n",
    "    # Color mapping\n",
    "    colors = {'downcast': 'dodgerblue', 'upcast': 'crimson', 'stationary': 'gainsboro'}\n",
    "    label_colors = [colors[label] for label in labels]\n",
    "\n",
    "    # Plot 1: Depth vs Time\n",
    "    ax.scatter(time, depth, c=label_colors, alpha=0.6, s=10)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Depth (m)')\n",
    "    ax.set_title('Depth vs Time (Classified)')\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aad61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL VERSION OF THE FUNCTION JUST FOR TESTING ----------------------------------------------- #\n",
    "def cast_time_QC(time, depth, time_limit=15, ref_depth=4):\n",
    "    \"\"\"\n",
    "    Marks times within ± interval around zero (or reference) depth crossings as good (1),\n",
    "    based on interval length = max_depth / sinking_speed.\n",
    "    \"\"\"\n",
    "\n",
    "    def datetime_to_minutes(t):\n",
    "        return (t - t[0]).astype(\"timedelta64[s]\").astype(int)/60\n",
    "\n",
    "    def split_updown(labels, trim: int=1):\n",
    "        midpoint = (len(labels)//2)\n",
    "        new_labs = np.full_like(labels, 2)\n",
    "        new_labs[0:midpoint-trim] = 1\n",
    "        new_labs[midpoint-trim:midpoint+trim] = 3\n",
    "        return new_labs\n",
    "    \n",
    "    def assign_cast_directions(flags):\n",
    "        \"\"\"\n",
    "        Assigns 1=downcast, 2=upcast, 3=stationary flags along an array.\n",
    "        Alternates between downcast and upcast segments, starting with downcast.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        flags : np.ndarray\n",
    "            Array containing 1 (cast) and 3 (stationary) values.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array of same shape, with upcast (2) assigned appropriately.\n",
    "        \"\"\"\n",
    "        flags = np.asarray(flags, dtype=int)\n",
    "        new_flags = flags.copy()\n",
    "        \n",
    "        # Identify cast regions between stationary (3) sequences\n",
    "        is_cast = flags == 1\n",
    "        cast_starts = np.where((~is_cast[:-1]) & is_cast[1:])[0] + 1\n",
    "        cast_ends = np.where((is_cast[:-1]) & (~is_cast[1:]))[0] + 1\n",
    "        \n",
    "        # Handle edge cases where array starts/ends with cast\n",
    "        if is_cast[0]:\n",
    "            cast_starts = np.r_[0, cast_starts]\n",
    "        if is_cast[-1]:\n",
    "            cast_ends = np.r_[cast_ends, len(flags)]\n",
    "        \n",
    "        # Alternate between downcast (1) and upcast (2)\n",
    "        cast_direction = 1  # start with downcast\n",
    "        for start, end in zip(cast_starts, cast_ends):\n",
    "            new_flags[start:end] = cast_direction\n",
    "            cast_direction = 2 if cast_direction == 1 else 1  # toggle direction\n",
    "        \n",
    "        return new_flags\n",
    "    \n",
    "    # Convert to arrays\n",
    "    time = np.asarray(time)\n",
    "    depth = np.asarray(depth)\n",
    "    t_min = datetime_to_minutes(time)\n",
    "\n",
    "    # Determine time window (dt)\n",
    "    max_time = np.max(t_min)\n",
    "    if max_time <= time_limit:\n",
    "        dt = max_time\n",
    "    elif time_limit + 15 <= max_time < time_limit + 30:\n",
    "        dt = 15\n",
    "    elif time_limit + 30 <= max_time < time_limit + 45:\n",
    "        dt = 30\n",
    "    elif time_limit + 45 <= max_time < time_limit + 60:\n",
    "        dt = 45\n",
    "    else:\n",
    "        dt = time_limit\n",
    "\n",
    "    if np.max(depth) > 225:\n",
    "        dt = dt + 5\n",
    "    if np.max(depth) > 325:\n",
    "        dt = dt + 5\n",
    "\n",
    "    # Reference crossings (depth ≤ ref_depth)\n",
    "    ref_times = t_min[depth <= ref_depth]\n",
    "    if ref_times.size == 0:\n",
    "        raise ValueError(\"No reference depth crossings found.\")\n",
    "\n",
    "    # For each ref_time, mark times within ±dt as good\n",
    "    cast_labels = np.full(time.size, 3, dtype=int)  # default bad\n",
    "    for ref_t in ref_times:\n",
    "        mask = np.abs(t_min - ref_t) <= dt\n",
    "        cast_labels[mask] = 1\n",
    "    \n",
    "    # Split short trajectories into down and up parts with a short stationary middle\n",
    "    if ~np.any(cast_labels == 3):\n",
    "        cast_labels = split_updown(cast_labels, trim=1)\n",
    "        return cast_labels\n",
    "    # Otherwise asign the up and downcast pairs for each ref time\n",
    "    cast_labels = assign_cast_directions(cast_labels)\n",
    "\n",
    "    return cast_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (\n",
    "    df.reset_index(level=['DEPTH'])\n",
    "      .groupby(level=0, group_keys=False)\n",
    "      .apply(lambda g: pd.Series(\n",
    "          cast_time_QC(g['TIME'].to_numpy(), g['DEPTH'].to_numpy(), ref_depth=4, time_limit=15),\n",
    "          index=g.index\n",
    "      ))\n",
    ")\n",
    "\n",
    "df = df.copy()\n",
    "df['CAST_FLAG'] = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23857ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CAST_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41715517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT A BUNCH OF CASTS COLOURED BY THEIR TIME_QC CLASSIFICATION ----------------------------------------------- #\n",
    "# NOTE: This will plot a lot of plots so be ready bucko... \n",
    "df_casts = df.copy()\n",
    "cast_ids = df_casts.index.get_level_values('TRAJECTORY').unique()\n",
    "N = (np.random.randint(0, len(cast_ids), 100)) # Choose 100 random casts to plot\n",
    "for i in N:\n",
    "    df_casts_i = df_casts[df_casts.index.get_level_values('TRAJECTORY') == cast_ids[i]]\n",
    "    time = (df_casts_i.TIME.values - df_casts_i.TIME.values[0]).astype('timedelta64[s]').view('int64')/60\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 3), dpi=200)\n",
    "    # Scatter plot\n",
    "    sc = ax.scatter(\n",
    "        time,\n",
    "        df_casts_i.index.get_level_values('DEPTH'),\n",
    "        c=df_casts_i['CAST_FLAG'],\n",
    "        s=3,\n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "    # Add legend entries for each flag\n",
    "    for flag_val, label in [(1, 'Down (1)'), (2, 'Up (2)'), (3, 'Stationary (3)')]:\n",
    "        ax.scatter([], [], c=sc.cmap(sc.norm(flag_val)), s=15, label=label)\n",
    "    # Labels, title, and axis orientation\n",
    "    ax.set_xlabel('Time (min)')\n",
    "    ax.set_ylabel('Depth (m)')\n",
    "    ax.set_title(f'Cast: {cast_ids[i]}')\n",
    "    ax.invert_yaxis()        # Flip so depth increases downward\n",
    "    ax.legend(title=\"CAST_FLAG\", loc='best', markerscale=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
